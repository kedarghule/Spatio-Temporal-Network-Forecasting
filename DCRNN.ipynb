{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric_temporal.dataset import METRLADatasetLoader\n",
    "from torch_geometric_temporal.signal import temporal_signal_split\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda') # cuda\n",
    "shuffle=True\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset\n",
    "\n",
    "loader = METRLADatasetLoader()\n",
    "\n",
    "dataset = loader.get_dataset()\n",
    "\n",
    "train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric_temporal.nn.recurrent import DCRNN\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda Available?:  True\n",
      "Current Device:  NVIDIA GeForce GTX 1060 with Max-Q Design\n"
     ]
    }
   ],
   "source": [
    "print(\"Cuda Available?: \", torch.cuda.is_available())\n",
    "print(\"Current Device: \", torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batches\n",
    "#https://github.com/benedekrozemberczki/pytorch_geometric_temporal/blob/master/examples/recurrent/a3tgcn2_example.py\n",
    "train_input = np.array(train_dataset.features) # (27399, 207, 2, 12)\n",
    "train_target = np.array(train_dataset.targets) # (27399, 207, 12)\n",
    "train_x_tensor = torch.from_numpy(train_input).type(torch.FloatTensor).to(DEVICE)  # (B, N, F, T)\n",
    "train_target_tensor = torch.from_numpy(train_target).type(torch.FloatTensor).to(DEVICE)  # (B, N, T)\n",
    "train_dataset_new = torch.utils.data.TensorDataset(train_x_tensor, train_target_tensor)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset_new, batch_size=batch_size, shuffle=shuffle,drop_last=True)\n",
    "\n",
    "\n",
    "test_input = np.array(test_dataset.features) # (, 207, 2, 12)\n",
    "test_target = np.array(test_dataset.targets) # (, 207, 12)\n",
    "test_x_tensor = torch.from_numpy(test_input).type(torch.FloatTensor).to(DEVICE)  # (B, N, F, T)\n",
    "test_target_tensor = torch.from_numpy(test_target).type(torch.FloatTensor).to(DEVICE)  # (B, N, T)\n",
    "test_dataset_new = torch.utils.data.TensorDataset(test_x_tensor, test_target_tensor)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset_new, batch_size=batch_size, shuffle=shuffle,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/benedekrozemberczki/pytorch_geometric_temporal/blob/master/examples/recurrent/dcrnn_example.py\n",
    "class RecurrentGCN(torch.nn.Module):\n",
    "    def __init__(self, node_features):\n",
    "        super(RecurrentGCN, self).__init__()\n",
    "        self.recurrent = DCRNN(node_features, 64, 5)\n",
    "        self.linear = torch.nn.Linear(64, 12)\n",
    "\n",
    "    # x needs to be 207 x 12\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        # x is B, N, F, T\n",
    "        x = x.permute(0,1,3,2)\n",
    "        # x is B, N, T, F\n",
    "        #print('x_in shape: ', x_in.shape)\n",
    "        # get just speed\n",
    "        x = x[:,:,:,0]\n",
    "        #reshape to (B*N, T)\n",
    "        x = x.reshape((x.shape[0]*x.shape[1], x.shape[2]))\n",
    "        h = self.recurrent(x, edge_index, edge_weight)\n",
    "        h = F.relu(h)\n",
    "        h = self.linear(h)\n",
    "        return h\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = 'cpu'\n",
    "\n",
    "model = RecurrentGCN(node_features = 12)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "lr_decay_ratio=0.1\n",
    "lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=steps, gamma=lr_decay_ratio)\n",
    "\n",
    "\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "loss_fn2 = F.l1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Loss:  6.22374852180481\n",
      "    Loss:  5.665551233291626\n",
      "    Loss:  5.421403424739838\n",
      "    Loss:  5.3200044733285905\n",
      "Epoch 0 train MAE: 5.2954\n",
      "    Loss:  4.846310782432556\n",
      "    Loss:  4.850142118930816\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m step\u001b[39m=\u001b[39m step\u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[39m#loss = torch.sqrt(loss)\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m loss_list\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39;49mitem())\n\u001b[0;32m     28\u001b[0m \u001b[39mif\u001b[39;00m step \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m :\n\u001b[0;32m     29\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m    Loss: \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39msum\u001b[39m(loss_list)\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(loss_list))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Loading the graph once because it's a static graph\n",
    "for snapshot in train_dataset:\n",
    "    static_edge_index = snapshot.edge_index.to(DEVICE)\n",
    "    static_edge_attr = snapshot.edge_attr.to(DEVICE)\n",
    "    break\n",
    "\n",
    "# Training the model \n",
    "model.train()\n",
    "\n",
    "for epoch in range(100):\n",
    "    step = 0\n",
    "    loss_list = []\n",
    "    for encoder_inputs, labels in train_loader:\n",
    "        y_hat = model(encoder_inputs, static_edge_index, static_edge_attr)         # Get model predictions\n",
    "        # reshape back to BxNxT\n",
    "        y_hat = y_hat.reshape((labels.shape))\n",
    "        mean = [53.59967, 0.4982691]\n",
    "        std = [20.209862, 0.28815305]\n",
    "        labels = labels*std[0] + mean[0]\n",
    "        y_hat = y_hat*std[0] + mean[0]\n",
    "        loss = loss_fn2(y_hat, labels) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        step= step+ 1\n",
    "        #loss = torch.sqrt(loss)\n",
    "        loss_list.append(loss.item())\n",
    "        if step % 100 == 0 :\n",
    "            print(\"    Loss: \", sum(loss_list)/len(loss_list))\n",
    "    lr_scheduler.step()\n",
    "    print(\"Epoch {} train MAE: {:.4f}\".format(epoch, sum(loss_list)/len(loss_list)))\n",
    "\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "#- Lets get some sample predictions for a specific horizon (e.g. 288/12 = 24 hours)\n",
    "#- The model always gets one hour and needs to predict the next hour\n",
    "\n",
    "model.eval()\n",
    "step = 0\n",
    "# Store for analysis\n",
    "total_loss = []\n",
    "for encoder_inputs, labels in test_loader:\n",
    "    # Get model predictions\n",
    "    y_hat = model(encoder_inputs, static_edge_index, static_edge_attr)\n",
    "    y_hat = y_hat.reshape((labels.shape))\n",
    "    # undo z-score\n",
    "    mean = [53.59967, 0.4982691]\n",
    "    std = [20.209862, 0.28815305]\n",
    "    labels = labels*std[0] + mean[0]\n",
    "    y_hat = y_hat*std[0] + mean[0]\n",
    "    # Mean squared error\n",
    "    #loss = loss_fn(y_hat, labels)\n",
    "    # Mean absolute error\n",
    "    loss = loss_fn2(y_hat, labels)\n",
    "    total_loss.append(loss.item())\n",
    "    # Store for analysis below\n",
    "    #test_labels.append(labels)\n",
    "    #predictions.append(y_hat)\n",
    "    \n",
    "\n",
    "print(\"Test MAE: {:.4f}\".format(sum(total_loss)/len(total_loss)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no batching\n",
    "# model.train()\n",
    "\n",
    "# for epoch in tqdm(range(10)):\n",
    "#     cost = 0\n",
    "#     for time, snapshot in enumerate(train_dataset):\n",
    "#         if(time == 0):\n",
    "#             edge_idx = snapshot.edge_index.to(device)\n",
    "#             edge_attr = snapshot.edge_attr.to(device)\n",
    "#         x_in = snapshot.x.permute(0,2,1)\n",
    "#         #print('x_in shape: ', x_in.shape)\n",
    "#         x_in = x_in[:,:,0]\n",
    "#         x_in = x_in.reshape((x_in.shape[0], x_in.shape[1]))\n",
    "#         n,f,t = snapshot.x.shape  # n = num nodes, f = num features, t = num timesteps\n",
    "        \n",
    "#         #x_in = snapshot.x.reshape((t, n*f))\n",
    "#         #print('new x_in shape: ', x_in.shape)\n",
    "#         x_in = x_in.to(device)\n",
    "        \n",
    "#         y_hat = model(x_in, edge_idx, edge_attr)\n",
    "#         y = snapshot.y.to(device)\n",
    "#         cost = cost + torch.mean((y_hat-y)**2)\n",
    "#         #print(\"y_hat shape: \", y_hat.shape)\n",
    "#         #print(\"y shape: \", y.shape)\n",
    "#         #print(time)\n",
    "#     cost = cost / (time+1)\n",
    "#     cost.backward()\n",
    "#     optimizer.step()\n",
    "#     optimizer.zero_grad()\n",
    "    \n",
    "# model.eval()\n",
    "# cost = 0\n",
    "# for time, snapshot in enumerate(test_dataset):\n",
    "#     x_in = snapshot.x.permute(0,2,1)\n",
    "#     #print('x_in shape: ', x_in.shape)\n",
    "#     x_in = x_in[:,:,0]\n",
    "#     x_in = x_in.reshape((x_in.shape[0], x_in.shape[1]))\n",
    "#     x_in = x_in.to(device)\n",
    "#     edge_idx = snapshot.edge_index.to(device)\n",
    "#     edge_attr = snapshot.edge_attr.to(device)\n",
    "#     y_hat = model(x_in, edge_idx, edge_attr)\n",
    "#     y = snapshot.y.to(device)\n",
    "#     #print(\"y_hat shape: \", y_hat.shape)\n",
    "#     #print(\"y shape: \", y.shape)\n",
    "#     cost = cost + torch.mean((y_hat-y)**2)\n",
    "# cost = cost / (time+1)\n",
    "# cost = cost.item()\n",
    "# print(\"MSE: {:.4f}\".format(cost))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
