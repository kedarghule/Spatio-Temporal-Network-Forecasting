{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20d5c50b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import typing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6631be",
   "metadata": {},
   "outputs": [],
   "source": [
    "route_distances = pd.read_csv(\n",
    "    \"PeMSD7_Full/PeMSD7_W_228.csv\", header=None\n",
    ")\n",
    "speeds_array = pd.read_csv(\"PeMSD7_Full/PeMSD7_V_228.csv\", header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2f83da",
   "metadata": {},
   "outputs": [],
   "source": [
    "route_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b67b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "speeds_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb97f356",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, data, stats):\n",
    "        self.__data = data\n",
    "        self.mean = stats['mean']\n",
    "        self.std = stats['std']\n",
    "\n",
    "    def get_data(self, type):\n",
    "        return self.__data[type]\n",
    "\n",
    "    def get_stats(self):\n",
    "        return {'mean': self.mean, 'std': self.std}\n",
    "\n",
    "    def get_len(self, type):\n",
    "        return len(self.__data[type])\n",
    "\n",
    "    def z_inverse(self, type):\n",
    "        return self.__data[type] * self.std + self.mean\n",
    "    \n",
    "def seq_gen(len_seq, data_seq, offset, n_frame, n_route, day_slot, C_0=1):\n",
    "    '''\n",
    "    Generate data in the form of standard sequence unit.\n",
    "    :param len_seq: int, the length of target date sequence.\n",
    "    :param data_seq: np.ndarray, source data / time-series.\n",
    "    :param offset:  int, the starting index of different dataset type.\n",
    "    :param n_frame: int, the number of frame within a standard sequence unit,\n",
    "                         which contains n_his = 12 and n_pred = 9 (3 /15 min, 6 /30 min & 9 /45 min).\n",
    "    :param n_route: int, the number of routes in the graph.\n",
    "    :param day_slot: int, the number of time slots per day, controlled by the time window (5 min as default).\n",
    "    :param C_0: int, the size of input channel.\n",
    "    :return: np.ndarray, [len_seq, n_frame, n_route, C_0].\n",
    "    '''\n",
    "    n_slot = day_slot - n_frame + 1\n",
    "\n",
    "    tmp_seq = np.zeros((len_seq * n_slot, n_frame, n_route, C_0))\n",
    "    for i in range(len_seq):\n",
    "        for j in range(n_slot):\n",
    "            sta = (i + offset) * day_slot + j\n",
    "            end = sta + n_frame\n",
    "            tmp_seq[i * n_slot + j, :, :, :] = np.reshape(data_seq[sta:end, :], [n_frame, n_route, C_0])\n",
    "    return tmp_seq\n",
    "\n",
    "def data_gen(file_path, data_config, n_route, n_frame=21, day_slot=288):\n",
    "    '''\n",
    "    Source file load and dataset generation.\n",
    "    :param file_path: str, the file path of data source.\n",
    "    :param data_config: tuple, the configs of dataset in train, validation, test.\n",
    "    :param n_route: int, the number of routes in the graph.\n",
    "    :param n_frame: int, the number of frame within a standard sequence unit,\n",
    "                         which contains n_his = 12 and n_pred = 9 (3 /15 min, 6 /30 min & 9 /45 min).\n",
    "    :param day_slot: int, the number of time slots per day, controlled by the time window (5 min as default).\n",
    "    :return: dict, dataset that contains training, validation and test with stats.\n",
    "    '''\n",
    "    n_train, n_val, n_test = data_config\n",
    "    \n",
    "    # generate training, validation and test data\n",
    "    try:\n",
    "        data_seq = pd.read_csv(file_path, header=None).values\n",
    "    except FileNotFoundError:\n",
    "        print(f'ERROR: input file was not found in {file_path}.')\n",
    "\n",
    "    seq_train = seq_gen(n_train, data_seq, 0, n_frame, n_route, day_slot)\n",
    "    seq_val = seq_gen(n_val, data_seq, n_train, n_frame, n_route, day_slot)\n",
    "    seq_test = seq_gen(n_test, data_seq, n_train + n_val, n_frame, n_route, day_slot)\n",
    "\n",
    "    # x_stats: dict, the stats for the train dataset, including the value of mean and standard deviation.\n",
    "    x_stats = {'mean': np.mean(seq_train), 'std': np.std(seq_train)}\n",
    "\n",
    "    # x_train, x_val, x_test: np.array, [sample_size, n_frame, n_route, channel_size].\n",
    "    x_train = z_score(seq_train, x_stats['mean'], x_stats['std'])\n",
    "    x_val = z_score(seq_val, x_stats['mean'], x_stats['std'])\n",
    "    x_test = z_score(seq_test, x_stats['mean'], x_stats['std'])\n",
    "\n",
    "    x_data = {'train': x_train, 'val': x_val, 'test': x_test}\n",
    "    dataset = Dataset(x_data, x_stats)\n",
    "    return dataset\n",
    "\n",
    "def z_score(x, mean, std):\n",
    "    '''\n",
    "    Z-score normalization function: $z = (X - \\mu) / \\sigma $,\n",
    "    where z is the z-score, X is the value of the element,\n",
    "    $\\mu$ is the population mean, and $\\sigma$ is the standard deviation.\n",
    "    :param x: np.ndarray, input array to be normalized.\n",
    "    :param mean: float, the value of mean.\n",
    "    :param std: float, the value of standard deviation.\n",
    "    :return: np.ndarray, z-score normalized array.\n",
    "    '''\n",
    "    return (x - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93472f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Loading dataset with Mean: 58.50, STD: 13.73\n"
     ]
    }
   ],
   "source": [
    "n_train, n_val, n_test = 34, 5, 5\n",
    "n, n_his, n_pred = 228, 12, 9\n",
    "PeMS = data_gen(\"PeMSD7_Full/PeMSD7_V_228.csv\", (n_train, n_val, n_test), n, n_his + n_pred)\n",
    "print(f'>> Loading dataset with Mean: {PeMS.mean:.2f}, STD: {PeMS.std:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8faa5500",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kedar\\anaconda3\\envs\\torch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9050872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4461f84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: KarateClub():\n",
      "======================\n",
      "Number of graphs: 1\n",
      "Number of features: 34\n",
      "Number of classes: 4\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import KarateClub\n",
    "\n",
    "dataset = KarateClub()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('======================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f72c467c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric_temporal.dataset import METRLADatasetLoader\n",
    "from torch_geometric_temporal.signal import StaticGraphTemporalSignal\n",
    "\n",
    "loader = METRLADatasetLoader()\n",
    "\n",
    "dataset = loader.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ac1d15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch_geometric_temporal.signal.static_graph_temporal_signal.StaticGraphTemporalSignal at 0x1e23f3217f0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ddb1f72",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of samples / sequences: \u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(\u001b[43mdataset\u001b[49m)))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples / sequences: \",  len(set(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2a9daa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric_temporal.dataset import METRLADatasetLoader\n",
    "from torch_geometric_temporal.signal import temporal_signal_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c6793321",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = METRLADatasetLoader()\n",
    "\n",
    "dataset = loader.get_dataset()\n",
    "\n",
    "train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6de5eb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e6f3343e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrafficLSTM(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size:  int, num_layers: int, sequence_len: int):\n",
    "        super().__init__()\n",
    "        self.sequence_len = sequence_len\n",
    "        self.input_size = input_size\n",
    "        self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, batch_first = True)\n",
    "        self.linear1 = nn.Linear(hidden_size*sequence_len, int(sequence_len*input_size/2))\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(int(sequence_len*input_size/2), sequence_len*input_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x.reshape(batch_size, -1)\n",
    "        #print(\"LSTM output: \", x.shape)\n",
    "        x = self.linear1(x)\n",
    "        #print(\"Linear output: \", x.shape)\n",
    "        x = self.relu1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = x.reshape(batch_size, self.sequence_len, self.input_size)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d91b30f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 0.2223, 0.5088,  ..., 0.2779, 0.3204, 1.0000])\n",
      "tensor([[  0,   0,   0,  ..., 206, 206, 206],\n",
      "        [  0,  13,  37,  ..., 187, 198, 206]])\n",
      "torch.Size([207, 12])\n",
      "(27399, 207, 2, 12)\n",
      "(27399, 207, 12)\n"
     ]
    }
   ],
   "source": [
    "temp = next(iter(dataset))\n",
    "print(temp.edge_attr)\n",
    "print(temp.edge_index)\n",
    "print(temp.y.shape)\n",
    "#print(len(train_dataset.features))\n",
    "#print(len(train_dataset.features[0]))\n",
    "features = np.array(train_dataset.features)\n",
    "print(features.shape)\n",
    "targets = np.array(train_dataset.targets)\n",
    "print(targets.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "fb436341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to take in features and make tensors of each point\n",
    "def create_dataset(train, test):\n",
    "    train_data_x = np.array(train.features)\n",
    "    # just get speed\n",
    "    train_data_x = train_data_x[:,:,0,:]\n",
    "    N, S, T = train_data_x.shape\n",
    "    #print(N,S,T)\n",
    "    #train_data_x = train_data_x.reshape((N, S*T))\n",
    "    train_data_y = np.array(train.targets)\n",
    "    #train_data_y = train_data_y.reshape((N, S*T))\n",
    "    x_train = torch.tensor(train_data_x).swapaxes(1,2)\n",
    "    y_train = torch.tensor(train_data_y).swapaxes(1,2)\n",
    "    #x_train = torch.tensor(train_data_x)\n",
    "    #y_train = torch.tensor(train_data_y)\n",
    "    print(x_train.shape)\n",
    "    print(y_train.shape)\n",
    "    return data.TensorDataset(x_train, y_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "82ee890f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27399, 12, 207])\n",
      "torch.Size([27399, 12, 207])\n",
      "label.shape: torch.Size([8, 12, 207])\n",
      "label: tensor([[[ 0.5332,  0.6940,  0.6692,  ...,  0.2796,  0.7620,  0.4095],\n",
      "         [ 0.4486,  0.7400,  0.5861,  ...,  0.1133,  0.7345,  0.4590],\n",
      "         [ 0.5146,  0.5022,  0.3167,  ...,  0.3847,  0.8044,  0.4157],\n",
      "         ...,\n",
      "         [ 0.4899,  0.3909,  0.4404,  ..., -0.1410,  0.6259,  0.4280],\n",
      "         [ 0.5751,  0.4981,  0.5696,  ...,  0.3442,  0.6741,  0.3167],\n",
      "         [ 0.4280,  0.7002,  0.6569,  ...,  0.1683,  0.6383,  0.2884]],\n",
      "\n",
      "        [[ 0.4486,  0.7400,  0.5861,  ...,  0.1133,  0.7345,  0.4590],\n",
      "         [ 0.5146,  0.5022,  0.3167,  ...,  0.3847,  0.8044,  0.4157],\n",
      "         [-2.6522, -2.6522, -2.6522,  ..., -2.6522, -2.6522, -2.6522],\n",
      "         ...,\n",
      "         [ 0.5751,  0.4981,  0.5696,  ...,  0.3442,  0.6741,  0.3167],\n",
      "         [ 0.4280,  0.7002,  0.6569,  ...,  0.1683,  0.6383,  0.2884],\n",
      "         [ 0.3724,  0.6631,  0.2425,  ..., -0.0235,  0.8115,  0.4899]],\n",
      "\n",
      "        [[ 0.5146,  0.5022,  0.3167,  ...,  0.3847,  0.8044,  0.4157],\n",
      "         [-2.6522, -2.6522, -2.6522,  ..., -2.6522, -2.6522, -2.6522],\n",
      "         [-2.6522, -2.6522, -2.6522,  ..., -2.6522, -2.6522, -2.6522],\n",
      "         ...,\n",
      "         [ 0.4280,  0.7002,  0.6569,  ...,  0.1683,  0.6383,  0.2884],\n",
      "         [ 0.3724,  0.6631,  0.2425,  ..., -0.0235,  0.8115,  0.4899],\n",
      "         [ 0.2452,  0.4486,  0.6026,  ..., -0.0517,  0.6246,  0.4321]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1847,  0.7620,  0.6960,  ...,  0.2012,  0.7620,  0.1847],\n",
      "         [ 0.6383,  0.5084,  0.7064,  ..., -0.1286,  0.7806,  0.3785],\n",
      "         [ 0.4961,  0.6754,  0.4775,  ..., -0.0792,  0.7435,  0.2858],\n",
      "         ...,\n",
      "         [ 0.4961,  0.6631,  0.0693,  ...,  0.0322,  0.6754,  0.2363],\n",
      "         [ 0.6521,  0.5916,  0.7180,  ...,  0.3717,  0.7235,  0.3882],\n",
      "         [ 0.1126,  0.5888,  0.3538,  ..., -0.1224,  0.6136,  0.3308]],\n",
      "\n",
      "        [[ 0.6383,  0.5084,  0.7064,  ..., -0.1286,  0.7806,  0.3785],\n",
      "         [ 0.4961,  0.6754,  0.4775,  ..., -0.0792,  0.7435,  0.2858],\n",
      "         [ 0.7497,  0.5765,  0.4899,  ..., -0.2462,  0.6940,  0.4033],\n",
      "         ...,\n",
      "         [ 0.6521,  0.5916,  0.7180,  ...,  0.3717,  0.7235,  0.3882],\n",
      "         [ 0.1126,  0.5888,  0.3538,  ..., -0.1224,  0.6136,  0.3308],\n",
      "         [ 0.5311,  0.6136,  0.7235,  ...,  0.2892,  0.7730,  0.4212]],\n",
      "\n",
      "        [[ 0.4961,  0.6754,  0.4775,  ..., -0.0792,  0.7435,  0.2858],\n",
      "         [ 0.7497,  0.5765,  0.4899,  ..., -0.2462,  0.6940,  0.4033],\n",
      "         [ 0.4899,  0.3909,  0.4404,  ..., -0.1410,  0.6259,  0.4280],\n",
      "         ...,\n",
      "         [ 0.1126,  0.5888,  0.3538,  ..., -0.1224,  0.6136,  0.3308],\n",
      "         [ 0.5311,  0.6136,  0.7235,  ...,  0.2892,  0.7730,  0.4212],\n",
      "         [ 0.5091,  0.3937,  0.7180,  ...,  0.3992,  0.6081,  0.0638]]])\n",
      "data.shape: torch.Size([8, 12, 207])\n",
      "2\n",
      "8\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "dataset = create_dataset(train_dataset, test_dataset)\n",
    "loader = data.DataLoader(dataset, batch_size = 8, drop_last=True)\n",
    "for idx, (label, data1) in enumerate(loader):\n",
    "    if idx > 0:\n",
    "        break\n",
    "    print('label.shape: {}'.format(label.shape))\n",
    "    print('label: {}'.format(label))\n",
    "    print('data.shape: {}'.format(data1.shape))\n",
    "temp = next(iter(loader))\n",
    "print(len(temp))\n",
    "print(len(temp[0]))\n",
    "print(len(temp[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "1c9128bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(model, dataloader, loss_func, device, optimizer):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (label, data1) in enumerate(dataloader):\n",
    "        label = label.to(device)\n",
    "        data1 = data1.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = None\n",
    "        ###########################################################################\n",
    "        # TODO: compute the logits of the input, get the loss, and do the         #\n",
    "        # gradient backpropagation.\n",
    "        ###########################################################################\n",
    "        out = model(data1)\n",
    "        if(idx == 0):\n",
    "            print(\"input shape: \", data1.shape)\n",
    "            print(\"output shape, \", out.shape)\n",
    "            print(\"label shape: \", label.shape)\n",
    "            print(\"out: \", out[0][0])\n",
    "            print(\"label: \", label[0][0])\n",
    "        loss = loss_func(out, label)\n",
    "        loss.backward()\n",
    "        ###########################################################################\n",
    "        #                             END OF YOUR CODE                            #\n",
    "        ###########################################################################\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        train_rmse = torch.sqrt(loss)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                  '| rmse {:8.3f}'.format(epoch, idx, len(dataloader),\n",
    "                                              train_rmse))\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(model, dataloader, loss_func, device):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, data1) in enumerate(dataloader):\n",
    "            label = label.to(device)\n",
    "            data1 = data1.to(device)\n",
    "            \n",
    "            ###########################################################################\n",
    "            # TODO: compute the logits of the input, get the loss.                    #\n",
    "            ###########################################################################\n",
    "            logits = model(data1)\n",
    "            loss = loss_func(logits, label)\n",
    "            ###########################################################################\n",
    "            #                             END OF YOUR CODE                            #\n",
    "            ###########################################################################\n",
    "            \n",
    "            total_acc += (logits.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "0d1318e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape:  torch.Size([8, 12, 207])\n",
      "output shape,  torch.Size([8, 12, 207])\n",
      "label shape:  torch.Size([8, 12, 207])\n",
      "out:  tensor([ 0.0126, -0.0483, -0.0025, -0.0257, -0.0033,  0.0090, -0.0059,  0.0535,\n",
      "        -0.0059,  0.0056,  0.0214, -0.0115,  0.0307, -0.0194,  0.0170,  0.0071,\n",
      "         0.0023, -0.0091,  0.0482,  0.0170, -0.0178,  0.0584, -0.0619,  0.0122,\n",
      "        -0.0243, -0.0016, -0.0361, -0.0636,  0.0320, -0.0056, -0.0523, -0.0033,\n",
      "         0.0146,  0.0129,  0.0034,  0.0400, -0.0219, -0.0330,  0.0213, -0.0245,\n",
      "         0.0010,  0.0062,  0.0323,  0.0061,  0.0463, -0.0196, -0.0188, -0.0005,\n",
      "         0.0099, -0.0384, -0.0645,  0.0310,  0.0042,  0.0107,  0.0180, -0.0139,\n",
      "         0.0474, -0.0106, -0.0015,  0.0028, -0.0191,  0.0198,  0.0490, -0.0051,\n",
      "        -0.0134,  0.0129, -0.0093,  0.0222, -0.0005,  0.0027, -0.0068, -0.0042,\n",
      "        -0.0579,  0.0237, -0.0188,  0.0022,  0.0349, -0.0145,  0.0179,  0.0315,\n",
      "         0.0265,  0.0104,  0.0573,  0.0308,  0.0401, -0.0157, -0.0336,  0.0309,\n",
      "        -0.0205, -0.0047, -0.0417, -0.0164,  0.0184, -0.0057,  0.0037, -0.0245,\n",
      "         0.0167, -0.0132, -0.0429, -0.0133,  0.0372, -0.0199, -0.0284,  0.0465,\n",
      "         0.0318, -0.0119, -0.0053, -0.0246, -0.0226,  0.0115,  0.0278,  0.0223,\n",
      "         0.0011,  0.0514, -0.0333, -0.0252, -0.0343,  0.0229, -0.0589,  0.0499,\n",
      "        -0.0086, -0.0266,  0.0285, -0.0128, -0.0244,  0.0146, -0.0118,  0.0138,\n",
      "        -0.0171,  0.0137,  0.0231,  0.0042,  0.0326, -0.0188,  0.0298, -0.0157,\n",
      "        -0.0071,  0.0222, -0.0042, -0.0278, -0.0538, -0.0029, -0.0065,  0.0074,\n",
      "        -0.0042, -0.0079,  0.0344,  0.0106, -0.0123,  0.0182, -0.0056,  0.0269,\n",
      "        -0.0271, -0.0242,  0.0079,  0.0245, -0.0138, -0.0053,  0.0284,  0.0280,\n",
      "         0.0457,  0.0207,  0.0048, -0.0099, -0.0257, -0.0141,  0.0419,  0.0032,\n",
      "        -0.0310, -0.0222,  0.0007, -0.0001, -0.0156,  0.0255,  0.0106,  0.0477,\n",
      "        -0.0296,  0.0199,  0.0058, -0.0404, -0.0059, -0.0040,  0.0099,  0.0549,\n",
      "        -0.0066,  0.0073,  0.0327,  0.0079, -0.0049,  0.0018, -0.0284, -0.0056,\n",
      "        -0.0318, -0.0189,  0.0011, -0.0002,  0.0186,  0.0116,  0.0091,  0.0383,\n",
      "         0.0242,  0.0109, -0.0109,  0.0038,  0.0538,  0.0101,  0.0198],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "label:  tensor([ 5.3317e-01,  6.9398e-01,  6.6924e-01,  3.9091e-01,  6.5687e-01,\n",
      "         7.4965e-01,  5.7028e-01,  6.6924e-01,  2.9814e-01,  4.5277e-01,\n",
      "         9.4030e-02,  6.3832e-01,  5.2699e-01,  7.3728e-01,  3.3525e-01,\n",
      "         6.8780e-01, -7.8425e-01,  4.7132e-01,  3.0432e-01,  4.2184e-01,\n",
      "         6.7543e-01, -6.1107e-01,  5.0734e-02,  2.2392e-01,  5.7028e-01,\n",
      "         5.2699e-01,  3.7854e-01,  4.5277e-01,  6.5687e-01, -3.0800e-01,\n",
      "         1.6825e-01,  7.0017e-01,  5.7028e-01,  6.5687e-01,  5.1462e-01,\n",
      "         4.1565e-01,  5.3317e-01,  3.5380e-01,  3.5380e-01,  4.3421e-01,\n",
      "         5.3936e-01,  6.1358e-01,  4.1565e-01,  5.5791e-01,  1.1259e-01,\n",
      "         7.0017e-01,  4.6514e-01,  3.2288e-01,  3.2906e-01,  4.2803e-01,\n",
      "        -5.6159e-01, -2.6471e-01,  5.7028e-01,  4.8988e-01,  1.0640e-01,\n",
      "         3.4143e-01, -1.0036e-01,  3.2906e-01,  5.0843e-01,  3.1051e-01,\n",
      "         5.4554e-01,  5.1462e-01, -5.4413e-02,  6.2595e-01,  7.2491e-01,\n",
      "         7.5584e-01,  6.3213e-01,  5.3936e-01,  7.0635e-01,  6.7543e-01,\n",
      "         4.7132e-01,  6.2595e-01,  5.4554e-01,  2.7340e-01,  7.2491e-01,\n",
      "        -6.6783e-02,  2.2392e-01,  3.7854e-01,  6.1976e-01,  7.8058e-01,\n",
      "         7.9913e-01,  4.8988e-01,  5.2699e-01,  7.1254e-01,  1.6207e-01,\n",
      "         5.3317e-01,  5.7647e-01,  6.0121e-01,  3.7854e-01,  4.9606e-01,\n",
      "         6.6306e-01,  8.1660e-02,  6.5687e-01,  5.8265e-01,  5.7028e-01,\n",
      "         1.9918e-01,  7.6821e-01,  6.3832e-01,  4.1565e-01,  6.8161e-01,\n",
      "         3.2288e-01,  5.8884e-01,  5.0225e-01,  6.2595e-01,  5.7647e-01,\n",
      "        -2.6522e+00, -2.6522e+00,  6.5687e-01,  4.9606e-01,  1.0640e-01,\n",
      "         6.8161e-01,  6.0121e-01,  4.7132e-01,  6.1358e-01,  7.4347e-01,\n",
      "         3.9091e-01,  6.6924e-01,  7.7439e-01,  5.8265e-01,  7.3110e-01,\n",
      "         3.8473e-01,  7.4384e-03,  5.7647e-01,  7.8058e-01,  4.2184e-01,\n",
      "        -1.7193e-01,  4.0328e-01,  6.5687e-01,  6.6924e-01,  2.4247e-01,\n",
      "         6.1976e-01,  6.3213e-01,  6.0121e-01,  4.0328e-01,  6.7543e-01,\n",
      "         5.6410e-01,  6.3213e-01,  5.0843e-01,  7.0635e-01,  4.9606e-01,\n",
      "         1.9918e-01,  5.4554e-01,  3.0432e-01,  4.8988e-01,  2.2392e-01,\n",
      "         6.5069e-01,  6.2595e-01,  3.4762e-01,  5.0225e-01,  7.8676e-01,\n",
      "         3.7854e-01, -2.3487e-02,  3.8473e-01,  4.7132e-01,  4.6514e-01,\n",
      "         4.8369e-01,  5.6919e-02,  5.7028e-01,  5.1462e-01,  6.8161e-01,\n",
      "         6.6924e-01,  7.2491e-01,  6.9398e-01,  7.8058e-01,  5.8884e-01,\n",
      "         6.9289e-02,  8.1150e-01,  7.2491e-01,  4.1565e-01,  5.3936e-01,\n",
      "         2.3629e-01,  5.3936e-01,  4.9606e-01,  5.0225e-01,  1.2533e-03,\n",
      "         8.0532e-01,  5.5173e-01,  4.3421e-01,  5.5173e-01, -7.2968e-02,\n",
      "         3.9710e-01,  4.6514e-01,  6.7013e-01,  6.9398e-01,  5.0843e-01,\n",
      "         4.7132e-01,  4.8369e-01,  5.2080e-01,  6.5687e-01,  8.0532e-01,\n",
      "         7.0017e-01,  4.1565e-01,  6.5069e-01,  1.9918e-01, -4.8227e-02,\n",
      "         7.6202e-01, -4.9974e-01, -3.9459e-01,  5.8884e-01,  5.3936e-01,\n",
      "         6.3478e-01,  6.5687e-01,  2.8577e-01,  7.6202e-01,  2.7958e-01,\n",
      "         7.6202e-01,  4.0947e-01], device='cuda:0')\n",
      "| epoch   1 |   500/ 3424 batches | rmse    0.493\n",
      "| epoch   1 |  1000/ 3424 batches | rmse    0.733\n",
      "| epoch   1 |  1500/ 3424 batches | rmse    0.726\n",
      "| epoch   1 |  2000/ 3424 batches | rmse    0.381\n",
      "| epoch   1 |  2500/ 3424 batches | rmse    0.652\n",
      "| epoch   1 |  3000/ 3424 batches | rmse    0.823\n",
      "input shape:  torch.Size([8, 12, 207])\n",
      "output shape,  torch.Size([8, 12, 207])\n",
      "label shape:  torch.Size([8, 12, 207])\n",
      "out:  tensor([ 0.1380,  0.1982,  0.3188, -0.0865,  0.0761, -0.2041,  0.2265,  0.1667,\n",
      "         0.1900,  0.3284, -0.1070,  0.1565, -0.0174,  0.2653,  0.0856,  0.0658,\n",
      "        -1.0719,  0.0617, -0.0746,  0.1732,  0.3173,  0.0295, -0.3461,  0.1913,\n",
      "         0.2915,  0.1422, -0.0396,  0.0611,  0.3435, -0.5110, -0.0394,  0.2493,\n",
      "         0.3245,  0.2108,  0.2948,  0.0652,  0.2457,  0.2529,  0.1641, -0.0146,\n",
      "         0.2995,  0.3504,  0.2288,  0.2150,  0.1755,  0.1734,  0.0821,  0.2258,\n",
      "         0.0212,  0.1639,  0.0144,  0.0373,  0.3773, -0.2259,  0.1576,  0.0504,\n",
      "        -0.3865,  0.0611,  0.1093,  0.1112,  0.1595,  0.2630,  0.1373,  0.2517,\n",
      "         0.1899,  0.0161,  0.2404,  0.3033,  0.3535,  0.3168,  0.1954,  0.1638,\n",
      "         0.1781,  0.2334,  0.3794, -0.2266,  0.0353,  0.0652,  0.3479,  0.3273,\n",
      "         0.2480,  0.1224,  0.2578,  0.2197,  0.0221,  0.3064,  0.2433,  0.2642,\n",
      "         0.2948,  0.2762,  0.2770, -0.4683,  0.2833,  0.2759,  0.2170,  0.2470,\n",
      "         0.4314,  0.3676,  0.0407,  0.2911,  0.1710,  0.2699,  0.1347,  0.2660,\n",
      "         0.2669,  0.1654, -0.0074,  0.2542,  0.3198,  0.0138,  0.1780,  0.3717,\n",
      "         0.2666,  0.1842,  0.2189,  0.2651,  0.2663,  0.2968,  0.2357,  0.3469,\n",
      "         0.2966, -0.1655,  0.3018,  0.2925,  0.2039, -0.0268, -0.0265,  0.3688,\n",
      "         0.3250,  0.1375,  0.1893,  0.1127,  0.3142,  0.2388,  0.3622,  0.1818,\n",
      "         0.3072,  0.1807,  0.2039,  0.2972,  0.0720,  0.3314,  0.1972,  0.1718,\n",
      "        -0.3209,  0.3573,  0.2736,  0.1560,  0.4030,  0.3488,  0.3037,  0.0429,\n",
      "        -0.0084,  0.0871,  0.0814,  0.2274, -0.1907,  0.2636,  0.1854,  0.2985,\n",
      "         0.2244,  0.3553,  0.3830,  0.3667,  0.1394,  0.0821,  0.2733,  0.3042,\n",
      "         0.2477,  0.2055,  0.1869,  0.1516,  0.1205,  0.1761, -0.3317,  0.2994,\n",
      "         0.3615,  0.1170,  0.1973, -0.1819, -0.1539, -0.0937,  0.3324,  0.3555,\n",
      "         0.1906,  0.2325,  0.2567,  0.1097,  0.3024, -0.0175,  0.3046,  0.0874,\n",
      "         0.1415, -0.0022,  0.0407,  0.3328, -1.0030, -0.5350,  0.4004,  0.2600,\n",
      "         0.1324,  0.1901,  0.0563,  0.2819,  0.1716,  0.3436,  0.1415],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "label:  tensor([ 5.3317e-01,  6.9398e-01,  6.6924e-01,  3.9091e-01,  6.5687e-01,\n",
      "         7.4965e-01,  5.7028e-01,  6.6924e-01,  2.9814e-01,  4.5277e-01,\n",
      "         9.4030e-02,  6.3832e-01,  5.2699e-01,  7.3728e-01,  3.3525e-01,\n",
      "         6.8780e-01, -7.8425e-01,  4.7132e-01,  3.0432e-01,  4.2184e-01,\n",
      "         6.7543e-01, -6.1107e-01,  5.0734e-02,  2.2392e-01,  5.7028e-01,\n",
      "         5.2699e-01,  3.7854e-01,  4.5277e-01,  6.5687e-01, -3.0800e-01,\n",
      "         1.6825e-01,  7.0017e-01,  5.7028e-01,  6.5687e-01,  5.1462e-01,\n",
      "         4.1565e-01,  5.3317e-01,  3.5380e-01,  3.5380e-01,  4.3421e-01,\n",
      "         5.3936e-01,  6.1358e-01,  4.1565e-01,  5.5791e-01,  1.1259e-01,\n",
      "         7.0017e-01,  4.6514e-01,  3.2288e-01,  3.2906e-01,  4.2803e-01,\n",
      "        -5.6159e-01, -2.6471e-01,  5.7028e-01,  4.8988e-01,  1.0640e-01,\n",
      "         3.4143e-01, -1.0036e-01,  3.2906e-01,  5.0843e-01,  3.1051e-01,\n",
      "         5.4554e-01,  5.1462e-01, -5.4413e-02,  6.2595e-01,  7.2491e-01,\n",
      "         7.5584e-01,  6.3213e-01,  5.3936e-01,  7.0635e-01,  6.7543e-01,\n",
      "         4.7132e-01,  6.2595e-01,  5.4554e-01,  2.7340e-01,  7.2491e-01,\n",
      "        -6.6783e-02,  2.2392e-01,  3.7854e-01,  6.1976e-01,  7.8058e-01,\n",
      "         7.9913e-01,  4.8988e-01,  5.2699e-01,  7.1254e-01,  1.6207e-01,\n",
      "         5.3317e-01,  5.7647e-01,  6.0121e-01,  3.7854e-01,  4.9606e-01,\n",
      "         6.6306e-01,  8.1660e-02,  6.5687e-01,  5.8265e-01,  5.7028e-01,\n",
      "         1.9918e-01,  7.6821e-01,  6.3832e-01,  4.1565e-01,  6.8161e-01,\n",
      "         3.2288e-01,  5.8884e-01,  5.0225e-01,  6.2595e-01,  5.7647e-01,\n",
      "        -2.6522e+00, -2.6522e+00,  6.5687e-01,  4.9606e-01,  1.0640e-01,\n",
      "         6.8161e-01,  6.0121e-01,  4.7132e-01,  6.1358e-01,  7.4347e-01,\n",
      "         3.9091e-01,  6.6924e-01,  7.7439e-01,  5.8265e-01,  7.3110e-01,\n",
      "         3.8473e-01,  7.4384e-03,  5.7647e-01,  7.8058e-01,  4.2184e-01,\n",
      "        -1.7193e-01,  4.0328e-01,  6.5687e-01,  6.6924e-01,  2.4247e-01,\n",
      "         6.1976e-01,  6.3213e-01,  6.0121e-01,  4.0328e-01,  6.7543e-01,\n",
      "         5.6410e-01,  6.3213e-01,  5.0843e-01,  7.0635e-01,  4.9606e-01,\n",
      "         1.9918e-01,  5.4554e-01,  3.0432e-01,  4.8988e-01,  2.2392e-01,\n",
      "         6.5069e-01,  6.2595e-01,  3.4762e-01,  5.0225e-01,  7.8676e-01,\n",
      "         3.7854e-01, -2.3487e-02,  3.8473e-01,  4.7132e-01,  4.6514e-01,\n",
      "         4.8369e-01,  5.6919e-02,  5.7028e-01,  5.1462e-01,  6.8161e-01,\n",
      "         6.6924e-01,  7.2491e-01,  6.9398e-01,  7.8058e-01,  5.8884e-01,\n",
      "         6.9289e-02,  8.1150e-01,  7.2491e-01,  4.1565e-01,  5.3936e-01,\n",
      "         2.3629e-01,  5.3936e-01,  4.9606e-01,  5.0225e-01,  1.2533e-03,\n",
      "         8.0532e-01,  5.5173e-01,  4.3421e-01,  5.5173e-01, -7.2968e-02,\n",
      "         3.9710e-01,  4.6514e-01,  6.7013e-01,  6.9398e-01,  5.0843e-01,\n",
      "         4.7132e-01,  4.8369e-01,  5.2080e-01,  6.5687e-01,  8.0532e-01,\n",
      "         7.0017e-01,  4.1565e-01,  6.5069e-01,  1.9918e-01, -4.8227e-02,\n",
      "         7.6202e-01, -4.9974e-01, -3.9459e-01,  5.8884e-01,  5.3936e-01,\n",
      "         6.3478e-01,  6.5687e-01,  2.8577e-01,  7.6202e-01,  2.7958e-01,\n",
      "         7.6202e-01,  4.0947e-01], device='cuda:0')\n",
      "| epoch   2 |   500/ 3424 batches | rmse    0.462\n",
      "| epoch   2 |  1000/ 3424 batches | rmse    0.658\n",
      "| epoch   2 |  1500/ 3424 batches | rmse    0.625\n",
      "| epoch   2 |  2000/ 3424 batches | rmse    0.522\n",
      "| epoch   2 |  2500/ 3424 batches | rmse    0.658\n",
      "| epoch   2 |  3000/ 3424 batches | rmse    0.824\n",
      "input shape:  torch.Size([8, 12, 207])\n",
      "output shape,  torch.Size([8, 12, 207])\n",
      "label shape:  torch.Size([8, 12, 207])\n",
      "out:  tensor([-7.4758e-02,  1.9120e-01,  3.0395e-01,  8.2695e-02,  3.8855e-01,\n",
      "        -3.1425e-01,  3.0828e-01,  2.0598e-02,  4.8006e-02,  2.8304e-01,\n",
      "        -1.4853e-01, -1.9105e-01,  3.4591e-01,  1.5096e-01,  5.3029e-03,\n",
      "         4.0328e-01, -1.0079e+00,  1.9523e-01, -4.1834e-01,  2.5243e-01,\n",
      "         2.5784e-01, -2.7481e-01, -4.2472e-01,  1.5993e-02,  2.9909e-01,\n",
      "        -1.0103e-01, -1.0072e-01,  4.4943e-02,  3.1406e-01, -3.8759e-01,\n",
      "        -4.3881e-02,  2.3449e-01,  3.1087e-01,  3.4472e-01,  2.9520e-01,\n",
      "        -2.4647e-01,  1.0013e-01,  5.6873e-04,  5.1193e-01, -8.0983e-02,\n",
      "         2.4047e-01,  3.4747e-01,  2.9777e-01,  1.6958e-01,  8.7750e-02,\n",
      "         1.3506e-01, -8.5469e-02,  1.3384e-01,  3.4478e-01, -2.9294e-02,\n",
      "        -3.0807e-01, -2.7495e-01,  2.3978e-01, -3.6775e-01,  1.0317e-01,\n",
      "        -1.1447e-01, -1.1438e-01,  1.5192e-01, -1.0708e-01, -1.1867e-02,\n",
      "         8.4529e-02,  7.6198e-02,  3.6373e-02,  2.3458e-01,  2.4576e-01,\n",
      "         8.2414e-02,  1.2311e-02,  2.6598e-01,  2.8612e-01,  2.5575e-01,\n",
      "         8.2819e-02,  2.3612e-01,  3.5711e-02,  1.1213e-01,  4.5799e-01,\n",
      "        -3.5511e-01, -1.2544e-01, -1.5609e-02,  3.4359e-01,  2.8949e-01,\n",
      "         2.5407e-01,  1.1693e-01,  1.9274e-01,  1.9561e-01, -1.4382e-02,\n",
      "         1.3226e-01,  2.4249e-01,  1.9385e-01,  2.4154e-01,  2.6493e-01,\n",
      "         2.0356e-01, -1.2176e-01,  9.5564e-02,  3.2988e-01,  3.0534e-01,\n",
      "        -2.7094e-02,  5.1039e-01,  4.2573e-01,  3.8814e-02,  2.5079e-01,\n",
      "         1.1650e-01,  7.8674e-02,  5.5695e-02,  1.6005e-01,  2.4811e-01,\n",
      "        -6.4056e-02, -5.7156e-01,  1.3948e-01,  1.8737e-01, -1.9605e-01,\n",
      "         8.5759e-02,  4.1792e-01,  7.9708e-02,  1.0901e-01, -1.2416e-01,\n",
      "         1.3465e-01,  9.9673e-02,  2.7852e-01,  1.5388e-01,  4.0961e-01,\n",
      "         4.8179e-03, -3.6824e-01,  2.6867e-01,  2.9771e-01,  7.9252e-02,\n",
      "        -3.2069e-01, -2.9572e-01,  3.7111e-01,  3.9163e-01, -1.2637e-01,\n",
      "         1.1902e-01,  4.5623e-02,  3.2531e-01,  3.2695e-01,  2.6782e-01,\n",
      "         2.0288e-01,  3.8711e-01,  1.4137e-01,  3.5049e-01,  1.4158e-01,\n",
      "        -7.8480e-02,  2.4630e-01,  2.1337e-01, -5.1233e-03,  6.4814e-02,\n",
      "         3.6618e-01,  2.2784e-01, -5.2185e-02,  3.4239e-01,  4.7558e-01,\n",
      "         3.2612e-01, -8.1536e-02, -1.2724e-01,  6.9864e-02,  2.0618e-01,\n",
      "         3.0576e-01, -3.8532e-01,  3.5434e-01,  1.1799e-01,  3.9205e-01,\n",
      "         4.1620e-01,  4.1916e-01,  4.2604e-01,  5.7009e-01,  1.4092e-01,\n",
      "        -1.7591e-01,  2.4507e-01,  2.3572e-01,  1.8013e-01,  1.6633e-01,\n",
      "        -5.9794e-02,  3.9478e-02,  8.4706e-02,  1.7824e-02, -4.8724e-01,\n",
      "         3.2596e-01,  3.6993e-01,  1.2267e-01,  1.4091e-02, -3.1890e-01,\n",
      "        -1.2390e-01, -1.6051e-03,  2.8084e-01,  3.9465e-01,  2.6891e-01,\n",
      "         1.3611e-01,  1.8848e-01,  3.3537e-01,  3.8394e-01, -1.8909e-01,\n",
      "         3.2352e-01,  4.0632e-01,  2.9651e-01,  3.5375e-01, -3.2440e-01,\n",
      "         4.1243e-01, -9.5092e-01, -6.8188e-01,  4.4554e-01,  7.7433e-03,\n",
      "        -6.5917e-02,  6.3627e-02, -2.0745e-02,  2.0597e-01,  1.3455e-01,\n",
      "         2.9758e-01,  1.3228e-01], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "label:  tensor([ 5.3317e-01,  6.9398e-01,  6.6924e-01,  3.9091e-01,  6.5687e-01,\n",
      "         7.4965e-01,  5.7028e-01,  6.6924e-01,  2.9814e-01,  4.5277e-01,\n",
      "         9.4030e-02,  6.3832e-01,  5.2699e-01,  7.3728e-01,  3.3525e-01,\n",
      "         6.8780e-01, -7.8425e-01,  4.7132e-01,  3.0432e-01,  4.2184e-01,\n",
      "         6.7543e-01, -6.1107e-01,  5.0734e-02,  2.2392e-01,  5.7028e-01,\n",
      "         5.2699e-01,  3.7854e-01,  4.5277e-01,  6.5687e-01, -3.0800e-01,\n",
      "         1.6825e-01,  7.0017e-01,  5.7028e-01,  6.5687e-01,  5.1462e-01,\n",
      "         4.1565e-01,  5.3317e-01,  3.5380e-01,  3.5380e-01,  4.3421e-01,\n",
      "         5.3936e-01,  6.1358e-01,  4.1565e-01,  5.5791e-01,  1.1259e-01,\n",
      "         7.0017e-01,  4.6514e-01,  3.2288e-01,  3.2906e-01,  4.2803e-01,\n",
      "        -5.6159e-01, -2.6471e-01,  5.7028e-01,  4.8988e-01,  1.0640e-01,\n",
      "         3.4143e-01, -1.0036e-01,  3.2906e-01,  5.0843e-01,  3.1051e-01,\n",
      "         5.4554e-01,  5.1462e-01, -5.4413e-02,  6.2595e-01,  7.2491e-01,\n",
      "         7.5584e-01,  6.3213e-01,  5.3936e-01,  7.0635e-01,  6.7543e-01,\n",
      "         4.7132e-01,  6.2595e-01,  5.4554e-01,  2.7340e-01,  7.2491e-01,\n",
      "        -6.6783e-02,  2.2392e-01,  3.7854e-01,  6.1976e-01,  7.8058e-01,\n",
      "         7.9913e-01,  4.8988e-01,  5.2699e-01,  7.1254e-01,  1.6207e-01,\n",
      "         5.3317e-01,  5.7647e-01,  6.0121e-01,  3.7854e-01,  4.9606e-01,\n",
      "         6.6306e-01,  8.1660e-02,  6.5687e-01,  5.8265e-01,  5.7028e-01,\n",
      "         1.9918e-01,  7.6821e-01,  6.3832e-01,  4.1565e-01,  6.8161e-01,\n",
      "         3.2288e-01,  5.8884e-01,  5.0225e-01,  6.2595e-01,  5.7647e-01,\n",
      "        -2.6522e+00, -2.6522e+00,  6.5687e-01,  4.9606e-01,  1.0640e-01,\n",
      "         6.8161e-01,  6.0121e-01,  4.7132e-01,  6.1358e-01,  7.4347e-01,\n",
      "         3.9091e-01,  6.6924e-01,  7.7439e-01,  5.8265e-01,  7.3110e-01,\n",
      "         3.8473e-01,  7.4384e-03,  5.7647e-01,  7.8058e-01,  4.2184e-01,\n",
      "        -1.7193e-01,  4.0328e-01,  6.5687e-01,  6.6924e-01,  2.4247e-01,\n",
      "         6.1976e-01,  6.3213e-01,  6.0121e-01,  4.0328e-01,  6.7543e-01,\n",
      "         5.6410e-01,  6.3213e-01,  5.0843e-01,  7.0635e-01,  4.9606e-01,\n",
      "         1.9918e-01,  5.4554e-01,  3.0432e-01,  4.8988e-01,  2.2392e-01,\n",
      "         6.5069e-01,  6.2595e-01,  3.4762e-01,  5.0225e-01,  7.8676e-01,\n",
      "         3.7854e-01, -2.3487e-02,  3.8473e-01,  4.7132e-01,  4.6514e-01,\n",
      "         4.8369e-01,  5.6919e-02,  5.7028e-01,  5.1462e-01,  6.8161e-01,\n",
      "         6.6924e-01,  7.2491e-01,  6.9398e-01,  7.8058e-01,  5.8884e-01,\n",
      "         6.9289e-02,  8.1150e-01,  7.2491e-01,  4.1565e-01,  5.3936e-01,\n",
      "         2.3629e-01,  5.3936e-01,  4.9606e-01,  5.0225e-01,  1.2533e-03,\n",
      "         8.0532e-01,  5.5173e-01,  4.3421e-01,  5.5173e-01, -7.2968e-02,\n",
      "         3.9710e-01,  4.6514e-01,  6.7013e-01,  6.9398e-01,  5.0843e-01,\n",
      "         4.7132e-01,  4.8369e-01,  5.2080e-01,  6.5687e-01,  8.0532e-01,\n",
      "         7.0017e-01,  4.1565e-01,  6.5069e-01,  1.9918e-01, -4.8227e-02,\n",
      "         7.6202e-01, -4.9974e-01, -3.9459e-01,  5.8884e-01,  5.3936e-01,\n",
      "         6.3478e-01,  6.5687e-01,  2.8577e-01,  7.6202e-01,  2.7958e-01,\n",
      "         7.6202e-01,  4.0947e-01], device='cuda:0')\n",
      "| epoch   3 |   500/ 3424 batches | rmse    0.426\n",
      "| epoch   3 |  1000/ 3424 batches | rmse    0.626\n",
      "| epoch   3 |  1500/ 3424 batches | rmse    0.666\n",
      "| epoch   3 |  2000/ 3424 batches | rmse    0.388\n",
      "| epoch   3 |  2500/ 3424 batches | rmse    0.632\n",
      "| epoch   3 |  3000/ 3424 batches | rmse    0.812\n",
      "input shape:  torch.Size([8, 12, 207])\n",
      "output shape,  torch.Size([8, 12, 207])\n",
      "label shape:  torch.Size([8, 12, 207])\n",
      "out:  tensor([ 0.0013,  0.1615,  0.2414, -0.0658,  0.1388, -0.1783,  0.2736,  0.1009,\n",
      "        -0.0484,  0.0135, -0.1234,  0.0680,  0.0873,  0.2539, -0.2004,  0.1312,\n",
      "        -1.1274,  0.0663, -0.1614,  0.2018,  0.3122, -0.0480, -0.6506,  0.0575,\n",
      "         0.3113,  0.0276,  0.0870,  0.0306,  0.2694, -0.6992, -0.0900,  0.2129,\n",
      "         0.2123,  0.2433,  0.2992,  0.0088, -0.1004,  0.1016, -0.0559, -0.2600,\n",
      "         0.1331,  0.2124,  0.2705,  0.2054,  0.1872,  0.1915, -0.0099,  0.1878,\n",
      "        -0.1573,  0.1019, -0.0873, -0.2194,  0.3369, -0.3391,  0.1637, -0.0561,\n",
      "        -0.5762,  0.0195,  0.0216, -0.0074,  0.1137,  0.1674,  0.1156,  0.2239,\n",
      "         0.1117,  0.0423,  0.1445,  0.3047,  0.2024,  0.3056,  0.0109,  0.1837,\n",
      "         0.1402,  0.1845,  0.3395, -0.2602, -0.0385, -0.2707,  0.2244,  0.2114,\n",
      "         0.2442,  0.0512,  0.2338,  0.0665, -0.3082,  0.1394,  0.2468,  0.1671,\n",
      "        -0.0392,  0.2970,  0.1876, -0.4214,  0.2144,  0.3000,  0.2391,  0.0785,\n",
      "         0.4410,  0.3430, -0.0621,  0.2914,  0.0250,  0.1494, -0.0732,  0.1223,\n",
      "         0.2852,  0.0496, -0.0860,  0.1986,  0.1206, -0.0763,  0.0514,  0.3341,\n",
      "         0.2531,  0.1831,  0.0375,  0.1687,  0.2346,  0.3057,  0.2580,  0.2983,\n",
      "         0.1623, -0.2123,  0.1189,  0.2771,  0.0999, -0.1188, -0.0878,  0.3727,\n",
      "         0.2664,  0.1123,  0.1891,  0.1402,  0.2120,  0.1112,  0.2744,  0.1312,\n",
      "         0.3121,  0.1485,  0.2385,  0.1498,  0.0528,  0.3359,  0.1845,  0.0976,\n",
      "        -0.1875,  0.3648,  0.3129,  0.0552,  0.2216,  0.1389,  0.2269, -0.2268,\n",
      "        -0.0261,  0.0948,  0.0568,  0.2288, -0.2696,  0.2145,  0.2018,  0.2949,\n",
      "         0.3133,  0.3319,  0.3315,  0.4357,  0.1615, -0.0353,  0.2700,  0.2586,\n",
      "         0.1630,  0.1247,  0.0585,  0.0616,  0.1200,  0.0774, -0.5742,  0.2793,\n",
      "         0.1334,  0.0919,  0.1034, -0.2521, -0.1486, -0.0707,  0.3175,  0.1992,\n",
      "         0.1657,  0.0192,  0.2311,  0.1963,  0.3157, -0.0412,  0.3076,  0.1570,\n",
      "         0.1639,  0.0888, -0.0104,  0.3464, -1.0779, -0.5543,  0.3467,  0.2177,\n",
      "         0.0973,  0.0308, -0.0562,  0.2419,  0.0998,  0.3338,  0.1241],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "label:  tensor([ 5.3317e-01,  6.9398e-01,  6.6924e-01,  3.9091e-01,  6.5687e-01,\n",
      "         7.4965e-01,  5.7028e-01,  6.6924e-01,  2.9814e-01,  4.5277e-01,\n",
      "         9.4030e-02,  6.3832e-01,  5.2699e-01,  7.3728e-01,  3.3525e-01,\n",
      "         6.8780e-01, -7.8425e-01,  4.7132e-01,  3.0432e-01,  4.2184e-01,\n",
      "         6.7543e-01, -6.1107e-01,  5.0734e-02,  2.2392e-01,  5.7028e-01,\n",
      "         5.2699e-01,  3.7854e-01,  4.5277e-01,  6.5687e-01, -3.0800e-01,\n",
      "         1.6825e-01,  7.0017e-01,  5.7028e-01,  6.5687e-01,  5.1462e-01,\n",
      "         4.1565e-01,  5.3317e-01,  3.5380e-01,  3.5380e-01,  4.3421e-01,\n",
      "         5.3936e-01,  6.1358e-01,  4.1565e-01,  5.5791e-01,  1.1259e-01,\n",
      "         7.0017e-01,  4.6514e-01,  3.2288e-01,  3.2906e-01,  4.2803e-01,\n",
      "        -5.6159e-01, -2.6471e-01,  5.7028e-01,  4.8988e-01,  1.0640e-01,\n",
      "         3.4143e-01, -1.0036e-01,  3.2906e-01,  5.0843e-01,  3.1051e-01,\n",
      "         5.4554e-01,  5.1462e-01, -5.4413e-02,  6.2595e-01,  7.2491e-01,\n",
      "         7.5584e-01,  6.3213e-01,  5.3936e-01,  7.0635e-01,  6.7543e-01,\n",
      "         4.7132e-01,  6.2595e-01,  5.4554e-01,  2.7340e-01,  7.2491e-01,\n",
      "        -6.6783e-02,  2.2392e-01,  3.7854e-01,  6.1976e-01,  7.8058e-01,\n",
      "         7.9913e-01,  4.8988e-01,  5.2699e-01,  7.1254e-01,  1.6207e-01,\n",
      "         5.3317e-01,  5.7647e-01,  6.0121e-01,  3.7854e-01,  4.9606e-01,\n",
      "         6.6306e-01,  8.1660e-02,  6.5687e-01,  5.8265e-01,  5.7028e-01,\n",
      "         1.9918e-01,  7.6821e-01,  6.3832e-01,  4.1565e-01,  6.8161e-01,\n",
      "         3.2288e-01,  5.8884e-01,  5.0225e-01,  6.2595e-01,  5.7647e-01,\n",
      "        -2.6522e+00, -2.6522e+00,  6.5687e-01,  4.9606e-01,  1.0640e-01,\n",
      "         6.8161e-01,  6.0121e-01,  4.7132e-01,  6.1358e-01,  7.4347e-01,\n",
      "         3.9091e-01,  6.6924e-01,  7.7439e-01,  5.8265e-01,  7.3110e-01,\n",
      "         3.8473e-01,  7.4384e-03,  5.7647e-01,  7.8058e-01,  4.2184e-01,\n",
      "        -1.7193e-01,  4.0328e-01,  6.5687e-01,  6.6924e-01,  2.4247e-01,\n",
      "         6.1976e-01,  6.3213e-01,  6.0121e-01,  4.0328e-01,  6.7543e-01,\n",
      "         5.6410e-01,  6.3213e-01,  5.0843e-01,  7.0635e-01,  4.9606e-01,\n",
      "         1.9918e-01,  5.4554e-01,  3.0432e-01,  4.8988e-01,  2.2392e-01,\n",
      "         6.5069e-01,  6.2595e-01,  3.4762e-01,  5.0225e-01,  7.8676e-01,\n",
      "         3.7854e-01, -2.3487e-02,  3.8473e-01,  4.7132e-01,  4.6514e-01,\n",
      "         4.8369e-01,  5.6919e-02,  5.7028e-01,  5.1462e-01,  6.8161e-01,\n",
      "         6.6924e-01,  7.2491e-01,  6.9398e-01,  7.8058e-01,  5.8884e-01,\n",
      "         6.9289e-02,  8.1150e-01,  7.2491e-01,  4.1565e-01,  5.3936e-01,\n",
      "         2.3629e-01,  5.3936e-01,  4.9606e-01,  5.0225e-01,  1.2533e-03,\n",
      "         8.0532e-01,  5.5173e-01,  4.3421e-01,  5.5173e-01, -7.2968e-02,\n",
      "         3.9710e-01,  4.6514e-01,  6.7013e-01,  6.9398e-01,  5.0843e-01,\n",
      "         4.7132e-01,  4.8369e-01,  5.2080e-01,  6.5687e-01,  8.0532e-01,\n",
      "         7.0017e-01,  4.1565e-01,  6.5069e-01,  1.9918e-01, -4.8227e-02,\n",
      "         7.6202e-01, -4.9974e-01, -3.9459e-01,  5.8884e-01,  5.3936e-01,\n",
      "         6.3478e-01,  6.5687e-01,  2.8577e-01,  7.6202e-01,  2.7958e-01,\n",
      "         7.6202e-01,  4.0947e-01], device='cuda:0')\n",
      "| epoch   4 |   500/ 3424 batches | rmse    0.443\n",
      "| epoch   4 |  1000/ 3424 batches | rmse    0.622\n",
      "| epoch   4 |  1500/ 3424 batches | rmse    0.594\n",
      "| epoch   4 |  2000/ 3424 batches | rmse    0.381\n",
      "| epoch   4 |  2500/ 3424 batches | rmse    0.650\n",
      "| epoch   4 |  3000/ 3424 batches | rmse    0.818\n",
      "input shape:  torch.Size([8, 12, 207])\n",
      "output shape,  torch.Size([8, 12, 207])\n",
      "label shape:  torch.Size([8, 12, 207])\n",
      "out:  tensor([-0.0590,  0.3387,  0.4210,  0.1416,  0.3440, -0.1220,  0.3877,  0.4054,\n",
      "         0.1888,  0.3307,  0.0354,  0.1995,  0.2561,  0.2560,  0.0690,  0.3473,\n",
      "        -0.9465,  0.2517, -0.1806,  0.3278,  0.4004, -0.0448, -0.4985,  0.0797,\n",
      "         0.4463,  0.0203,  0.0721,  0.2134,  0.4475, -0.3305,  0.0645,  0.4075,\n",
      "         0.4454,  0.3820,  0.3933, -0.0163,  0.2240,  0.0994,  0.2002, -0.1743,\n",
      "         0.3312,  0.4598,  0.3608,  0.2566,  0.2992,  0.3463,  0.2910,  0.2079,\n",
      "         0.0599,  0.1181, -0.0768, -0.1561,  0.3449, -0.1981,  0.2327,  0.2484,\n",
      "        -0.2704,  0.2129,  0.0418,  0.1840,  0.1590,  0.1806,  0.1576,  0.3033,\n",
      "         0.3636,  0.2701,  0.3954,  0.4304,  0.4019,  0.3317,  0.2071,  0.3449,\n",
      "         0.1670,  0.1987,  0.5111, -0.2684,  0.0039,  0.0584,  0.4535,  0.4062,\n",
      "         0.3649,  0.1594,  0.2932,  0.3085,  0.0688,  0.4932,  0.3595,  0.3317,\n",
      "         0.3249,  0.3933,  0.3838, -0.1567,  0.4804,  0.3897,  0.3672,  0.0840,\n",
      "         0.5185,  0.4789,  0.1400,  0.4252,  0.2126,  0.1544,  0.1418,  0.2789,\n",
      "         0.3783,  0.1018, -0.1562,  0.5230,  0.5287, -0.0944,  0.2739,  0.4321,\n",
      "         0.2056,  0.2320, -0.0136,  0.2767,  0.2276,  0.3982,  0.3359,  0.4805,\n",
      "         0.1219, -0.2120,  0.3640,  0.4503,  0.1295, -0.1887, -0.0516,  0.4140,\n",
      "         0.4642,  0.0768,  0.2510,  0.1660,  0.4377,  0.1783,  0.2997,  0.3265,\n",
      "         0.4367,  0.1918,  0.4317,  0.1872,  0.0606,  0.3431,  0.2512,  0.1213,\n",
      "         0.0151,  0.4686,  0.3931,  0.0623,  0.4443,  0.3031,  0.4014,  0.0302,\n",
      "         0.1010,  0.2537,  0.2338,  0.3168, -0.2129,  0.3970,  0.2344,  0.3837,\n",
      "         0.3554,  0.4771,  0.4851,  0.4910,  0.2095, -0.0737,  0.3205,  0.4226,\n",
      "         0.3885,  0.3593,  0.0298,  0.2836,  0.1729,  0.3361, -0.6400,  0.4305,\n",
      "         0.4348,  0.2768,  0.2101, -0.1289, -0.1051,  0.0088,  0.4056,  0.4716,\n",
      "         0.3874,  0.2832,  0.3117,  0.2771,  0.4574, -0.0396,  0.3940,  0.3587,\n",
      "         0.3471,  0.2733, -0.0504,  0.4906, -0.8850, -0.5445,  0.4939,  0.1297,\n",
      "         0.1433,  0.2632,  0.1851,  0.4055,  0.2709,  0.3806,  0.2045],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "label:  tensor([ 5.3317e-01,  6.9398e-01,  6.6924e-01,  3.9091e-01,  6.5687e-01,\n",
      "         7.4965e-01,  5.7028e-01,  6.6924e-01,  2.9814e-01,  4.5277e-01,\n",
      "         9.4030e-02,  6.3832e-01,  5.2699e-01,  7.3728e-01,  3.3525e-01,\n",
      "         6.8780e-01, -7.8425e-01,  4.7132e-01,  3.0432e-01,  4.2184e-01,\n",
      "         6.7543e-01, -6.1107e-01,  5.0734e-02,  2.2392e-01,  5.7028e-01,\n",
      "         5.2699e-01,  3.7854e-01,  4.5277e-01,  6.5687e-01, -3.0800e-01,\n",
      "         1.6825e-01,  7.0017e-01,  5.7028e-01,  6.5687e-01,  5.1462e-01,\n",
      "         4.1565e-01,  5.3317e-01,  3.5380e-01,  3.5380e-01,  4.3421e-01,\n",
      "         5.3936e-01,  6.1358e-01,  4.1565e-01,  5.5791e-01,  1.1259e-01,\n",
      "         7.0017e-01,  4.6514e-01,  3.2288e-01,  3.2906e-01,  4.2803e-01,\n",
      "        -5.6159e-01, -2.6471e-01,  5.7028e-01,  4.8988e-01,  1.0640e-01,\n",
      "         3.4143e-01, -1.0036e-01,  3.2906e-01,  5.0843e-01,  3.1051e-01,\n",
      "         5.4554e-01,  5.1462e-01, -5.4413e-02,  6.2595e-01,  7.2491e-01,\n",
      "         7.5584e-01,  6.3213e-01,  5.3936e-01,  7.0635e-01,  6.7543e-01,\n",
      "         4.7132e-01,  6.2595e-01,  5.4554e-01,  2.7340e-01,  7.2491e-01,\n",
      "        -6.6783e-02,  2.2392e-01,  3.7854e-01,  6.1976e-01,  7.8058e-01,\n",
      "         7.9913e-01,  4.8988e-01,  5.2699e-01,  7.1254e-01,  1.6207e-01,\n",
      "         5.3317e-01,  5.7647e-01,  6.0121e-01,  3.7854e-01,  4.9606e-01,\n",
      "         6.6306e-01,  8.1660e-02,  6.5687e-01,  5.8265e-01,  5.7028e-01,\n",
      "         1.9918e-01,  7.6821e-01,  6.3832e-01,  4.1565e-01,  6.8161e-01,\n",
      "         3.2288e-01,  5.8884e-01,  5.0225e-01,  6.2595e-01,  5.7647e-01,\n",
      "        -2.6522e+00, -2.6522e+00,  6.5687e-01,  4.9606e-01,  1.0640e-01,\n",
      "         6.8161e-01,  6.0121e-01,  4.7132e-01,  6.1358e-01,  7.4347e-01,\n",
      "         3.9091e-01,  6.6924e-01,  7.7439e-01,  5.8265e-01,  7.3110e-01,\n",
      "         3.8473e-01,  7.4384e-03,  5.7647e-01,  7.8058e-01,  4.2184e-01,\n",
      "        -1.7193e-01,  4.0328e-01,  6.5687e-01,  6.6924e-01,  2.4247e-01,\n",
      "         6.1976e-01,  6.3213e-01,  6.0121e-01,  4.0328e-01,  6.7543e-01,\n",
      "         5.6410e-01,  6.3213e-01,  5.0843e-01,  7.0635e-01,  4.9606e-01,\n",
      "         1.9918e-01,  5.4554e-01,  3.0432e-01,  4.8988e-01,  2.2392e-01,\n",
      "         6.5069e-01,  6.2595e-01,  3.4762e-01,  5.0225e-01,  7.8676e-01,\n",
      "         3.7854e-01, -2.3487e-02,  3.8473e-01,  4.7132e-01,  4.6514e-01,\n",
      "         4.8369e-01,  5.6919e-02,  5.7028e-01,  5.1462e-01,  6.8161e-01,\n",
      "         6.6924e-01,  7.2491e-01,  6.9398e-01,  7.8058e-01,  5.8884e-01,\n",
      "         6.9289e-02,  8.1150e-01,  7.2491e-01,  4.1565e-01,  5.3936e-01,\n",
      "         2.3629e-01,  5.3936e-01,  4.9606e-01,  5.0225e-01,  1.2533e-03,\n",
      "         8.0532e-01,  5.5173e-01,  4.3421e-01,  5.5173e-01, -7.2968e-02,\n",
      "         3.9710e-01,  4.6514e-01,  6.7013e-01,  6.9398e-01,  5.0843e-01,\n",
      "         4.7132e-01,  4.8369e-01,  5.2080e-01,  6.5687e-01,  8.0532e-01,\n",
      "         7.0017e-01,  4.1565e-01,  6.5069e-01,  1.9918e-01, -4.8227e-02,\n",
      "         7.6202e-01, -4.9974e-01, -3.9459e-01,  5.8884e-01,  5.3936e-01,\n",
      "         6.3478e-01,  6.5687e-01,  2.8577e-01,  7.6202e-01,  2.7958e-01,\n",
      "         7.6202e-01,  4.0947e-01], device='cuda:0')\n",
      "| epoch   5 |   500/ 3424 batches | rmse    0.459\n",
      "| epoch   5 |  1000/ 3424 batches | rmse    0.604\n",
      "| epoch   5 |  1500/ 3424 batches | rmse    0.624\n",
      "| epoch   5 |  2000/ 3424 batches | rmse    0.389\n",
      "| epoch   5 |  2500/ 3424 batches | rmse    0.637\n",
      "| epoch   5 |  3000/ 3424 batches | rmse    0.682\n",
      "input shape:  torch.Size([8, 12, 207])\n",
      "output shape,  torch.Size([8, 12, 207])\n",
      "label shape:  torch.Size([8, 12, 207])\n",
      "out:  tensor([ 6.7796e-04,  3.6001e-01,  4.4060e-01,  1.0377e-01,  2.6035e-01,\n",
      "        -7.4410e-02,  3.7233e-01,  3.6924e-01,  2.3507e-01,  3.8456e-01,\n",
      "         7.8774e-02,  2.0457e-01,  1.3355e-01,  3.1145e-01,  1.2105e-01,\n",
      "         2.6980e-01, -9.7633e-01,  2.2698e-01, -1.1700e-01,  2.8336e-01,\n",
      "         3.9177e-01,  1.1683e-02, -4.5981e-01,  9.2219e-02,  4.5935e-01,\n",
      "         6.7492e-02,  3.2964e-02,  2.3731e-01,  4.6300e-01, -3.6867e-01,\n",
      "         6.4917e-02,  3.9764e-01,  3.9820e-01,  3.6078e-01,  3.9831e-01,\n",
      "         5.5247e-02,  2.2108e-01,  2.0843e-02,  2.4954e-01, -1.3584e-01,\n",
      "         3.4180e-01,  3.4645e-01,  3.8030e-01,  2.8032e-01,  3.7086e-01,\n",
      "         4.1225e-01,  2.6037e-01,  2.1162e-01,  8.5243e-02,  1.8824e-01,\n",
      "        -2.2442e-02, -1.4058e-01,  3.7021e-01, -1.8326e-01,  2.4592e-01,\n",
      "         2.4874e-01, -2.9647e-01,  1.5745e-01,  1.0419e-01,  2.2083e-01,\n",
      "         1.6197e-01,  1.6375e-01,  2.0114e-01,  2.7789e-01,  3.6540e-01,\n",
      "         2.8100e-01,  3.7601e-01,  4.6186e-01,  3.8442e-01,  3.3630e-01,\n",
      "         2.1111e-01,  3.4528e-01,  1.8715e-01,  1.9986e-01,  4.6827e-01,\n",
      "        -2.5416e-01,  2.4662e-02,  1.3815e-01,  4.6944e-01,  4.1993e-01,\n",
      "         3.7472e-01,  1.2028e-01,  2.8523e-01,  2.9788e-01,  9.9550e-02,\n",
      "         4.4768e-01,  3.6339e-01,  3.4793e-01,  3.6986e-01,  4.1017e-01,\n",
      "         4.0226e-01, -2.1686e-01,  4.9454e-01,  3.9905e-01,  3.3969e-01,\n",
      "         1.0428e-01,  5.2303e-01,  4.6086e-01,  1.1489e-01,  4.3822e-01,\n",
      "         2.3010e-01,  2.0050e-01,  1.3732e-01,  2.6305e-01,  3.7413e-01,\n",
      "         1.6593e-01, -1.2736e-01,  5.1143e-01,  4.8247e-01,  8.3955e-03,\n",
      "         2.6551e-01,  4.3724e-01,  2.0949e-01,  2.2949e-01, -5.0152e-02,\n",
      "         2.6285e-01,  3.0044e-01,  4.1623e-01,  3.7549e-01,  4.3371e-01,\n",
      "         1.5744e-01, -1.6740e-01,  3.8571e-01,  4.8469e-01,  1.1133e-01,\n",
      "        -1.8548e-01, -1.5498e-02,  3.9692e-01,  4.3667e-01,  1.5115e-01,\n",
      "         2.8159e-01,  1.5420e-01,  4.4160e-01,  1.8263e-01,  3.4695e-01,\n",
      "         3.4607e-01,  4.5505e-01,  1.6392e-01,  3.9315e-01,  2.2867e-01,\n",
      "         9.2921e-02,  3.5518e-01,  2.5394e-01,  1.6436e-01, -7.5768e-02,\n",
      "         4.6894e-01,  2.5983e-01,  1.2013e-01,  3.5743e-01,  2.6006e-01,\n",
      "         3.0730e-01,  7.4305e-02,  1.6828e-01,  3.1346e-01,  2.0956e-01,\n",
      "         2.8246e-01, -1.4822e-01,  3.7159e-01,  2.0658e-01,  3.5379e-01,\n",
      "         2.9448e-01,  4.7258e-01,  4.7693e-01,  4.3527e-01,  1.9059e-01,\n",
      "        -6.3122e-02,  3.2399e-01,  4.4307e-01,  3.7372e-01,  3.5861e-01,\n",
      "         9.5839e-02,  2.8018e-01,  1.5895e-01,  3.1900e-01, -5.6377e-01,\n",
      "         3.7274e-01,  4.3239e-01,  2.9692e-01,  2.6604e-01, -7.2658e-02,\n",
      "        -1.7269e-01, -3.1245e-02,  4.2295e-01,  4.6394e-01,  3.8521e-01,\n",
      "         3.2580e-01,  3.3338e-01,  1.9075e-01,  4.3953e-01,  1.1308e-02,\n",
      "         3.9482e-01,  2.6679e-01,  3.1397e-01,  1.7379e-01,  2.8022e-02,\n",
      "         4.5394e-01, -9.1793e-01, -5.4385e-01,  4.7190e-01,  1.9564e-01,\n",
      "         1.8956e-01,  2.4841e-01,  1.9494e-01,  4.4013e-01,  3.0154e-01,\n",
      "         3.9747e-01,  2.2185e-01], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "label:  tensor([ 5.3317e-01,  6.9398e-01,  6.6924e-01,  3.9091e-01,  6.5687e-01,\n",
      "         7.4965e-01,  5.7028e-01,  6.6924e-01,  2.9814e-01,  4.5277e-01,\n",
      "         9.4030e-02,  6.3832e-01,  5.2699e-01,  7.3728e-01,  3.3525e-01,\n",
      "         6.8780e-01, -7.8425e-01,  4.7132e-01,  3.0432e-01,  4.2184e-01,\n",
      "         6.7543e-01, -6.1107e-01,  5.0734e-02,  2.2392e-01,  5.7028e-01,\n",
      "         5.2699e-01,  3.7854e-01,  4.5277e-01,  6.5687e-01, -3.0800e-01,\n",
      "         1.6825e-01,  7.0017e-01,  5.7028e-01,  6.5687e-01,  5.1462e-01,\n",
      "         4.1565e-01,  5.3317e-01,  3.5380e-01,  3.5380e-01,  4.3421e-01,\n",
      "         5.3936e-01,  6.1358e-01,  4.1565e-01,  5.5791e-01,  1.1259e-01,\n",
      "         7.0017e-01,  4.6514e-01,  3.2288e-01,  3.2906e-01,  4.2803e-01,\n",
      "        -5.6159e-01, -2.6471e-01,  5.7028e-01,  4.8988e-01,  1.0640e-01,\n",
      "         3.4143e-01, -1.0036e-01,  3.2906e-01,  5.0843e-01,  3.1051e-01,\n",
      "         5.4554e-01,  5.1462e-01, -5.4413e-02,  6.2595e-01,  7.2491e-01,\n",
      "         7.5584e-01,  6.3213e-01,  5.3936e-01,  7.0635e-01,  6.7543e-01,\n",
      "         4.7132e-01,  6.2595e-01,  5.4554e-01,  2.7340e-01,  7.2491e-01,\n",
      "        -6.6783e-02,  2.2392e-01,  3.7854e-01,  6.1976e-01,  7.8058e-01,\n",
      "         7.9913e-01,  4.8988e-01,  5.2699e-01,  7.1254e-01,  1.6207e-01,\n",
      "         5.3317e-01,  5.7647e-01,  6.0121e-01,  3.7854e-01,  4.9606e-01,\n",
      "         6.6306e-01,  8.1660e-02,  6.5687e-01,  5.8265e-01,  5.7028e-01,\n",
      "         1.9918e-01,  7.6821e-01,  6.3832e-01,  4.1565e-01,  6.8161e-01,\n",
      "         3.2288e-01,  5.8884e-01,  5.0225e-01,  6.2595e-01,  5.7647e-01,\n",
      "        -2.6522e+00, -2.6522e+00,  6.5687e-01,  4.9606e-01,  1.0640e-01,\n",
      "         6.8161e-01,  6.0121e-01,  4.7132e-01,  6.1358e-01,  7.4347e-01,\n",
      "         3.9091e-01,  6.6924e-01,  7.7439e-01,  5.8265e-01,  7.3110e-01,\n",
      "         3.8473e-01,  7.4384e-03,  5.7647e-01,  7.8058e-01,  4.2184e-01,\n",
      "        -1.7193e-01,  4.0328e-01,  6.5687e-01,  6.6924e-01,  2.4247e-01,\n",
      "         6.1976e-01,  6.3213e-01,  6.0121e-01,  4.0328e-01,  6.7543e-01,\n",
      "         5.6410e-01,  6.3213e-01,  5.0843e-01,  7.0635e-01,  4.9606e-01,\n",
      "         1.9918e-01,  5.4554e-01,  3.0432e-01,  4.8988e-01,  2.2392e-01,\n",
      "         6.5069e-01,  6.2595e-01,  3.4762e-01,  5.0225e-01,  7.8676e-01,\n",
      "         3.7854e-01, -2.3487e-02,  3.8473e-01,  4.7132e-01,  4.6514e-01,\n",
      "         4.8369e-01,  5.6919e-02,  5.7028e-01,  5.1462e-01,  6.8161e-01,\n",
      "         6.6924e-01,  7.2491e-01,  6.9398e-01,  7.8058e-01,  5.8884e-01,\n",
      "         6.9289e-02,  8.1150e-01,  7.2491e-01,  4.1565e-01,  5.3936e-01,\n",
      "         2.3629e-01,  5.3936e-01,  4.9606e-01,  5.0225e-01,  1.2533e-03,\n",
      "         8.0532e-01,  5.5173e-01,  4.3421e-01,  5.5173e-01, -7.2968e-02,\n",
      "         3.9710e-01,  4.6514e-01,  6.7013e-01,  6.9398e-01,  5.0843e-01,\n",
      "         4.7132e-01,  4.8369e-01,  5.2080e-01,  6.5687e-01,  8.0532e-01,\n",
      "         7.0017e-01,  4.1565e-01,  6.5069e-01,  1.9918e-01, -4.8227e-02,\n",
      "         7.6202e-01, -4.9974e-01, -3.9459e-01,  5.8884e-01,  5.3936e-01,\n",
      "         6.3478e-01,  6.5687e-01,  2.8577e-01,  7.6202e-01,  2.7958e-01,\n",
      "         7.6202e-01,  4.0947e-01], device='cuda:0')\n",
      "| epoch   6 |   500/ 3424 batches | rmse    0.440\n",
      "| epoch   6 |  1000/ 3424 batches | rmse    0.606\n",
      "| epoch   6 |  1500/ 3424 batches | rmse    0.546\n",
      "| epoch   6 |  2000/ 3424 batches | rmse    0.370\n",
      "| epoch   6 |  2500/ 3424 batches | rmse    0.626\n",
      "| epoch   6 |  3000/ 3424 batches | rmse    0.753\n",
      "input shape:  torch.Size([8, 12, 207])\n",
      "output shape,  torch.Size([8, 12, 207])\n",
      "label shape:  torch.Size([8, 12, 207])\n",
      "out:  tensor([-0.4510,  0.3272,  0.4265,  0.1001,  0.3500, -0.0893,  0.4165,  0.3654,\n",
      "         0.1397,  0.2788,  0.0054,  0.1869,  0.2292,  0.2065,  0.0561,  0.3580,\n",
      "        -0.8821,  0.2006, -0.2146,  0.3268,  0.4193, -0.0787, -0.5940,  0.0699,\n",
      "         0.4343,  0.0555,  0.0610,  0.2236,  0.4769, -0.3186,  0.0765,  0.3481,\n",
      "         0.4329,  0.4201,  0.3810, -0.0333,  0.1929, -0.3799,  0.2076, -0.2951,\n",
      "         0.3523,  0.2814,  0.2587,  0.2545,  0.2377,  0.2756,  0.2616,  0.2233,\n",
      "         0.0792,  0.1304, -0.1150, -0.2332,  0.3362, -0.1239,  0.2455,  0.2350,\n",
      "        -0.3180,  0.1814,  0.0206,  0.1492,  0.1722,  0.0957,  0.0965,  0.2508,\n",
      "         0.3508,  0.2933,  0.3625,  0.4144,  0.3562,  0.2731,  0.1718,  0.2888,\n",
      "         0.1481,  0.1720,  0.4597, -0.2973,  0.0179,  0.0085,  0.4446,  0.4162,\n",
      "         0.3167,  0.1012,  0.2873,  0.2932, -0.0230,  0.4838,  0.3235,  0.2846,\n",
      "         0.2758,  0.3825,  0.3980, -0.1780,  0.4600,  0.4285,  0.3245,  0.0863,\n",
      "         0.4449,  0.4393,  0.1039,  0.3982,  0.1606,  0.2051,  0.1160,  0.2685,\n",
      "         0.3709,  0.1243, -0.2293,  0.4934,  0.4949,  0.0156,  0.3396,  0.4022,\n",
      "         0.1310,  0.1652, -0.4789,  0.2797,  0.2091,  0.3448,  0.3195,  0.4339,\n",
      "         0.1338, -0.1940,  0.3962,  0.4523,  0.1224, -0.1796, -0.0576,  0.3625,\n",
      "         0.4224,  0.1221,  0.2399,  0.1277,  0.4422,  0.1628,  0.3348,  0.3364,\n",
      "         0.4620,  0.1356,  0.4378,  0.1754,  0.0389,  0.3434,  0.2358,  0.0830,\n",
      "         0.0057,  0.4526,  0.2206,  0.1214,  0.2743,  0.2959,  0.2126, -0.0226,\n",
      "         0.0381,  0.1798,  0.2132,  0.2163, -0.2126,  0.3472,  0.1764,  0.3160,\n",
      "         0.3412,  0.4277,  0.4276,  0.4638,  0.1765, -0.1003,  0.3328,  0.3914,\n",
      "         0.4604,  0.4506,  0.0376,  0.3682,  0.1280,  0.4235, -0.9552,  0.3777,\n",
      "         0.4338,  0.2847,  0.2143, -0.1002, -0.2712, -0.1527,  0.3985,  0.4966,\n",
      "         0.3876,  0.2351,  0.3037,  0.2497,  0.3935, -0.0282,  0.3322,  0.3450,\n",
      "         0.3033,  0.2769, -0.0727,  0.4235, -0.8433, -0.5839,  0.4427,  0.1133,\n",
      "         0.1267,  0.3493,  0.2661,  0.3974,  0.2738,  0.3501,  0.1514],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "label:  tensor([ 5.3317e-01,  6.9398e-01,  6.6924e-01,  3.9091e-01,  6.5687e-01,\n",
      "         7.4965e-01,  5.7028e-01,  6.6924e-01,  2.9814e-01,  4.5277e-01,\n",
      "         9.4030e-02,  6.3832e-01,  5.2699e-01,  7.3728e-01,  3.3525e-01,\n",
      "         6.8780e-01, -7.8425e-01,  4.7132e-01,  3.0432e-01,  4.2184e-01,\n",
      "         6.7543e-01, -6.1107e-01,  5.0734e-02,  2.2392e-01,  5.7028e-01,\n",
      "         5.2699e-01,  3.7854e-01,  4.5277e-01,  6.5687e-01, -3.0800e-01,\n",
      "         1.6825e-01,  7.0017e-01,  5.7028e-01,  6.5687e-01,  5.1462e-01,\n",
      "         4.1565e-01,  5.3317e-01,  3.5380e-01,  3.5380e-01,  4.3421e-01,\n",
      "         5.3936e-01,  6.1358e-01,  4.1565e-01,  5.5791e-01,  1.1259e-01,\n",
      "         7.0017e-01,  4.6514e-01,  3.2288e-01,  3.2906e-01,  4.2803e-01,\n",
      "        -5.6159e-01, -2.6471e-01,  5.7028e-01,  4.8988e-01,  1.0640e-01,\n",
      "         3.4143e-01, -1.0036e-01,  3.2906e-01,  5.0843e-01,  3.1051e-01,\n",
      "         5.4554e-01,  5.1462e-01, -5.4413e-02,  6.2595e-01,  7.2491e-01,\n",
      "         7.5584e-01,  6.3213e-01,  5.3936e-01,  7.0635e-01,  6.7543e-01,\n",
      "         4.7132e-01,  6.2595e-01,  5.4554e-01,  2.7340e-01,  7.2491e-01,\n",
      "        -6.6783e-02,  2.2392e-01,  3.7854e-01,  6.1976e-01,  7.8058e-01,\n",
      "         7.9913e-01,  4.8988e-01,  5.2699e-01,  7.1254e-01,  1.6207e-01,\n",
      "         5.3317e-01,  5.7647e-01,  6.0121e-01,  3.7854e-01,  4.9606e-01,\n",
      "         6.6306e-01,  8.1660e-02,  6.5687e-01,  5.8265e-01,  5.7028e-01,\n",
      "         1.9918e-01,  7.6821e-01,  6.3832e-01,  4.1565e-01,  6.8161e-01,\n",
      "         3.2288e-01,  5.8884e-01,  5.0225e-01,  6.2595e-01,  5.7647e-01,\n",
      "        -2.6522e+00, -2.6522e+00,  6.5687e-01,  4.9606e-01,  1.0640e-01,\n",
      "         6.8161e-01,  6.0121e-01,  4.7132e-01,  6.1358e-01,  7.4347e-01,\n",
      "         3.9091e-01,  6.6924e-01,  7.7439e-01,  5.8265e-01,  7.3110e-01,\n",
      "         3.8473e-01,  7.4384e-03,  5.7647e-01,  7.8058e-01,  4.2184e-01,\n",
      "        -1.7193e-01,  4.0328e-01,  6.5687e-01,  6.6924e-01,  2.4247e-01,\n",
      "         6.1976e-01,  6.3213e-01,  6.0121e-01,  4.0328e-01,  6.7543e-01,\n",
      "         5.6410e-01,  6.3213e-01,  5.0843e-01,  7.0635e-01,  4.9606e-01,\n",
      "         1.9918e-01,  5.4554e-01,  3.0432e-01,  4.8988e-01,  2.2392e-01,\n",
      "         6.5069e-01,  6.2595e-01,  3.4762e-01,  5.0225e-01,  7.8676e-01,\n",
      "         3.7854e-01, -2.3487e-02,  3.8473e-01,  4.7132e-01,  4.6514e-01,\n",
      "         4.8369e-01,  5.6919e-02,  5.7028e-01,  5.1462e-01,  6.8161e-01,\n",
      "         6.6924e-01,  7.2491e-01,  6.9398e-01,  7.8058e-01,  5.8884e-01,\n",
      "         6.9289e-02,  8.1150e-01,  7.2491e-01,  4.1565e-01,  5.3936e-01,\n",
      "         2.3629e-01,  5.3936e-01,  4.9606e-01,  5.0225e-01,  1.2533e-03,\n",
      "         8.0532e-01,  5.5173e-01,  4.3421e-01,  5.5173e-01, -7.2968e-02,\n",
      "         3.9710e-01,  4.6514e-01,  6.7013e-01,  6.9398e-01,  5.0843e-01,\n",
      "         4.7132e-01,  4.8369e-01,  5.2080e-01,  6.5687e-01,  8.0532e-01,\n",
      "         7.0017e-01,  4.1565e-01,  6.5069e-01,  1.9918e-01, -4.8227e-02,\n",
      "         7.6202e-01, -4.9974e-01, -3.9459e-01,  5.8884e-01,  5.3936e-01,\n",
      "         6.3478e-01,  6.5687e-01,  2.8577e-01,  7.6202e-01,  2.7958e-01,\n",
      "         7.6202e-01,  4.0947e-01], device='cuda:0')\n",
      "| epoch   7 |   500/ 3424 batches | rmse    0.430\n",
      "| epoch   7 |  1000/ 3424 batches | rmse    0.602\n",
      "| epoch   7 |  1500/ 3424 batches | rmse    0.510\n",
      "| epoch   7 |  2000/ 3424 batches | rmse    0.373\n",
      "| epoch   7 |  2500/ 3424 batches | rmse    0.630\n",
      "| epoch   7 |  3000/ 3424 batches | rmse    0.748\n",
      "input shape:  torch.Size([8, 12, 207])\n",
      "output shape,  torch.Size([8, 12, 207])\n",
      "label shape:  torch.Size([8, 12, 207])\n",
      "out:  tensor([-0.4175,  0.3160,  0.4711,  0.1135,  0.4183, -0.1103,  0.3894,  0.3530,\n",
      "         0.1375,  0.3164,  0.0290,  0.1162,  0.3358,  0.1954,  0.0589,  0.4283,\n",
      "        -0.9042,  0.2103, -0.2769,  0.2957,  0.3783, -0.1479, -0.5097, -0.0591,\n",
      "         0.3963, -0.0329,  0.0334,  0.1965,  0.4866, -0.2330,  0.0505,  0.3664,\n",
      "         0.4575,  0.4000,  0.3636, -0.0996,  0.2175, -0.3860,  0.2884, -0.2243,\n",
      "         0.3726,  0.3565,  0.2121,  0.2136,  0.2323,  0.2721,  0.2376,  0.2026,\n",
      "         0.1650,  0.0759, -0.1782, -0.3385,  0.3355, -0.1233,  0.1400,  0.2098,\n",
      "        -0.2466,  0.1306, -0.0346,  0.1469,  0.1420,  0.0273,  0.0011,  0.2406,\n",
      "         0.4190,  0.3153,  0.3273,  0.3614,  0.3692,  0.2403,  0.1987,  0.2476,\n",
      "         0.0862,  0.1586,  0.4059, -0.3299, -0.0227,  0.0511,  0.4942,  0.4536,\n",
      "         0.2845,  0.0926,  0.2372,  0.3088,  0.0255,  0.4866,  0.3044,  0.2995,\n",
      "         0.3189,  0.3713,  0.3962, -0.1249,  0.4437,  0.3682,  0.2885, -0.0173,\n",
      "         0.4305,  0.3746,  0.1069,  0.3949,  0.1778,  0.0967,  0.1283,  0.2610,\n",
      "         0.3712,  0.0024, -0.3411,  0.5039,  0.5417, -0.0975,  0.3651,  0.3480,\n",
      "         0.0970,  0.1263, -0.4771,  0.1551,  0.1143,  0.3114,  0.2698,  0.3669,\n",
      "         0.0092, -0.2253,  0.4330,  0.4407, -0.0284, -0.3137, -0.1379,  0.3163,\n",
      "         0.3738,  0.0347,  0.2054,  0.0871,  0.4819,  0.1493,  0.2760,  0.3098,\n",
      "         0.4269,  0.1010,  0.4208,  0.1225, -0.0491,  0.3385,  0.1696,  0.0152,\n",
      "         0.0794,  0.3400,  0.2278,  0.0235,  0.3420,  0.2010,  0.2988, -0.0102,\n",
      "         0.0327,  0.1822,  0.1648,  0.1980, -0.2478,  0.2902,  0.1450,  0.2923,\n",
      "         0.3372,  0.3876,  0.3703,  0.4498,  0.1296, -0.2442,  0.2683,  0.4032,\n",
      "         0.4504,  0.4570, -0.0426,  0.3429,  0.0858,  0.4221, -1.0316,  0.3268,\n",
      "         0.4883,  0.2529,  0.1699, -0.1443, -0.2263, -0.0682,  0.3785,  0.5530,\n",
      "         0.4011,  0.2417,  0.2489,  0.2781,  0.3729, -0.0488,  0.3006,  0.4210,\n",
      "         0.3036,  0.3556, -0.1596,  0.4044, -0.8580, -0.6300,  0.3738,  0.0130,\n",
      "         0.0805,  0.3675,  0.2795,  0.3560,  0.2975,  0.2892,  0.1058],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "label:  tensor([ 5.3317e-01,  6.9398e-01,  6.6924e-01,  3.9091e-01,  6.5687e-01,\n",
      "         7.4965e-01,  5.7028e-01,  6.6924e-01,  2.9814e-01,  4.5277e-01,\n",
      "         9.4030e-02,  6.3832e-01,  5.2699e-01,  7.3728e-01,  3.3525e-01,\n",
      "         6.8780e-01, -7.8425e-01,  4.7132e-01,  3.0432e-01,  4.2184e-01,\n",
      "         6.7543e-01, -6.1107e-01,  5.0734e-02,  2.2392e-01,  5.7028e-01,\n",
      "         5.2699e-01,  3.7854e-01,  4.5277e-01,  6.5687e-01, -3.0800e-01,\n",
      "         1.6825e-01,  7.0017e-01,  5.7028e-01,  6.5687e-01,  5.1462e-01,\n",
      "         4.1565e-01,  5.3317e-01,  3.5380e-01,  3.5380e-01,  4.3421e-01,\n",
      "         5.3936e-01,  6.1358e-01,  4.1565e-01,  5.5791e-01,  1.1259e-01,\n",
      "         7.0017e-01,  4.6514e-01,  3.2288e-01,  3.2906e-01,  4.2803e-01,\n",
      "        -5.6159e-01, -2.6471e-01,  5.7028e-01,  4.8988e-01,  1.0640e-01,\n",
      "         3.4143e-01, -1.0036e-01,  3.2906e-01,  5.0843e-01,  3.1051e-01,\n",
      "         5.4554e-01,  5.1462e-01, -5.4413e-02,  6.2595e-01,  7.2491e-01,\n",
      "         7.5584e-01,  6.3213e-01,  5.3936e-01,  7.0635e-01,  6.7543e-01,\n",
      "         4.7132e-01,  6.2595e-01,  5.4554e-01,  2.7340e-01,  7.2491e-01,\n",
      "        -6.6783e-02,  2.2392e-01,  3.7854e-01,  6.1976e-01,  7.8058e-01,\n",
      "         7.9913e-01,  4.8988e-01,  5.2699e-01,  7.1254e-01,  1.6207e-01,\n",
      "         5.3317e-01,  5.7647e-01,  6.0121e-01,  3.7854e-01,  4.9606e-01,\n",
      "         6.6306e-01,  8.1660e-02,  6.5687e-01,  5.8265e-01,  5.7028e-01,\n",
      "         1.9918e-01,  7.6821e-01,  6.3832e-01,  4.1565e-01,  6.8161e-01,\n",
      "         3.2288e-01,  5.8884e-01,  5.0225e-01,  6.2595e-01,  5.7647e-01,\n",
      "        -2.6522e+00, -2.6522e+00,  6.5687e-01,  4.9606e-01,  1.0640e-01,\n",
      "         6.8161e-01,  6.0121e-01,  4.7132e-01,  6.1358e-01,  7.4347e-01,\n",
      "         3.9091e-01,  6.6924e-01,  7.7439e-01,  5.8265e-01,  7.3110e-01,\n",
      "         3.8473e-01,  7.4384e-03,  5.7647e-01,  7.8058e-01,  4.2184e-01,\n",
      "        -1.7193e-01,  4.0328e-01,  6.5687e-01,  6.6924e-01,  2.4247e-01,\n",
      "         6.1976e-01,  6.3213e-01,  6.0121e-01,  4.0328e-01,  6.7543e-01,\n",
      "         5.6410e-01,  6.3213e-01,  5.0843e-01,  7.0635e-01,  4.9606e-01,\n",
      "         1.9918e-01,  5.4554e-01,  3.0432e-01,  4.8988e-01,  2.2392e-01,\n",
      "         6.5069e-01,  6.2595e-01,  3.4762e-01,  5.0225e-01,  7.8676e-01,\n",
      "         3.7854e-01, -2.3487e-02,  3.8473e-01,  4.7132e-01,  4.6514e-01,\n",
      "         4.8369e-01,  5.6919e-02,  5.7028e-01,  5.1462e-01,  6.8161e-01,\n",
      "         6.6924e-01,  7.2491e-01,  6.9398e-01,  7.8058e-01,  5.8884e-01,\n",
      "         6.9289e-02,  8.1150e-01,  7.2491e-01,  4.1565e-01,  5.3936e-01,\n",
      "         2.3629e-01,  5.3936e-01,  4.9606e-01,  5.0225e-01,  1.2533e-03,\n",
      "         8.0532e-01,  5.5173e-01,  4.3421e-01,  5.5173e-01, -7.2968e-02,\n",
      "         3.9710e-01,  4.6514e-01,  6.7013e-01,  6.9398e-01,  5.0843e-01,\n",
      "         4.7132e-01,  4.8369e-01,  5.2080e-01,  6.5687e-01,  8.0532e-01,\n",
      "         7.0017e-01,  4.1565e-01,  6.5069e-01,  1.9918e-01, -4.8227e-02,\n",
      "         7.6202e-01, -4.9974e-01, -3.9459e-01,  5.8884e-01,  5.3936e-01,\n",
      "         6.3478e-01,  6.5687e-01,  2.8577e-01,  7.6202e-01,  2.7958e-01,\n",
      "         7.6202e-01,  4.0947e-01], device='cuda:0')\n",
      "| epoch   8 |   500/ 3424 batches | rmse    0.443\n",
      "| epoch   8 |  1000/ 3424 batches | rmse    0.584\n",
      "| epoch   8 |  1500/ 3424 batches | rmse    0.585\n",
      "| epoch   8 |  2000/ 3424 batches | rmse    0.358\n",
      "| epoch   8 |  2500/ 3424 batches | rmse    0.633\n",
      "| epoch   8 |  3000/ 3424 batches | rmse    0.714\n",
      "input shape:  torch.Size([8, 12, 207])\n",
      "output shape,  torch.Size([8, 12, 207])\n",
      "label shape:  torch.Size([8, 12, 207])\n",
      "out:  tensor([-0.0174,  0.3477,  0.4509,  0.1145,  0.3480, -0.1338,  0.3482,  0.3551,\n",
      "         0.1548,  0.3602,  0.0490,  0.0536,  0.2239,  0.2362,  0.0605,  0.3503,\n",
      "        -0.9278,  0.2208, -0.2776,  0.2868,  0.3888, -0.1366, -0.4651, -0.0468,\n",
      "         0.4212, -0.0794, -0.0176,  0.2092,  0.4623, -0.2324,  0.0608,  0.4038,\n",
      "         0.4229,  0.3685,  0.3632, -0.0923,  0.2337,  0.0903,  0.3222, -0.1048,\n",
      "         0.3551,  0.4672,  0.3287,  0.2273,  0.2596,  0.3272,  0.2291,  0.1891,\n",
      "         0.1712,  0.0318, -0.1663, -0.3156,  0.3698, -0.1795,  0.1450,  0.2083,\n",
      "        -0.2286,  0.1510, -0.0459,  0.1501,  0.1496,  0.0653,  0.0311,  0.2739,\n",
      "         0.4005,  0.3162,  0.3095,  0.3790,  0.3846,  0.2765,  0.1923,  0.2837,\n",
      "         0.1076,  0.1768,  0.4481, -0.3077, -0.0285,  0.1041,  0.4867,  0.4384,\n",
      "         0.3048,  0.1206,  0.2431,  0.3088,  0.0705,  0.4599,  0.2998,  0.3268,\n",
      "         0.3385,  0.3833,  0.3855, -0.2071,  0.4539,  0.3628,  0.2921, -0.0689,\n",
      "         0.5189,  0.3922,  0.0964,  0.4181,  0.2047,  0.0471,  0.1166,  0.2631,\n",
      "         0.3771, -0.1114, -0.3768,  0.4876,  0.5223, -0.1565,  0.3141,  0.4061,\n",
      "         0.0808,  0.1470, -0.0090,  0.2147,  0.1327,  0.3550,  0.2653,  0.3993,\n",
      "        -0.0256, -0.1959,  0.3909,  0.4698, -0.0330, -0.3598, -0.1642,  0.3679,\n",
      "         0.4025, -0.0543,  0.2251,  0.1109,  0.4697,  0.1555,  0.2539,  0.3354,\n",
      "         0.4235,  0.1277,  0.4297,  0.1057, -0.0516,  0.3503,  0.2145,  0.0036,\n",
      "        -0.0216,  0.3857,  0.3180, -0.0345,  0.4405,  0.1431,  0.4471,  0.0142,\n",
      "         0.0495,  0.2344,  0.1738,  0.2667, -0.2443,  0.3067,  0.1717,  0.3465,\n",
      "         0.3052,  0.4106,  0.4040,  0.4752,  0.1441, -0.2421,  0.2550,  0.4053,\n",
      "         0.4168,  0.4060, -0.0919,  0.2928,  0.0997,  0.3573, -0.7708,  0.3576,\n",
      "         0.4685,  0.2633,  0.1669, -0.1426, -0.1504,  0.0380,  0.3988,  0.5307,\n",
      "         0.4170,  0.2596,  0.2565,  0.2066,  0.3916, -0.0380,  0.3330,  0.3494,\n",
      "         0.3193,  0.2614, -0.1712,  0.4428, -0.8612, -0.6264,  0.4010,  0.0079,\n",
      "         0.0860,  0.3041,  0.2262,  0.3828,  0.2911,  0.3348,  0.1817],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "label:  tensor([ 5.3317e-01,  6.9398e-01,  6.6924e-01,  3.9091e-01,  6.5687e-01,\n",
      "         7.4965e-01,  5.7028e-01,  6.6924e-01,  2.9814e-01,  4.5277e-01,\n",
      "         9.4030e-02,  6.3832e-01,  5.2699e-01,  7.3728e-01,  3.3525e-01,\n",
      "         6.8780e-01, -7.8425e-01,  4.7132e-01,  3.0432e-01,  4.2184e-01,\n",
      "         6.7543e-01, -6.1107e-01,  5.0734e-02,  2.2392e-01,  5.7028e-01,\n",
      "         5.2699e-01,  3.7854e-01,  4.5277e-01,  6.5687e-01, -3.0800e-01,\n",
      "         1.6825e-01,  7.0017e-01,  5.7028e-01,  6.5687e-01,  5.1462e-01,\n",
      "         4.1565e-01,  5.3317e-01,  3.5380e-01,  3.5380e-01,  4.3421e-01,\n",
      "         5.3936e-01,  6.1358e-01,  4.1565e-01,  5.5791e-01,  1.1259e-01,\n",
      "         7.0017e-01,  4.6514e-01,  3.2288e-01,  3.2906e-01,  4.2803e-01,\n",
      "        -5.6159e-01, -2.6471e-01,  5.7028e-01,  4.8988e-01,  1.0640e-01,\n",
      "         3.4143e-01, -1.0036e-01,  3.2906e-01,  5.0843e-01,  3.1051e-01,\n",
      "         5.4554e-01,  5.1462e-01, -5.4413e-02,  6.2595e-01,  7.2491e-01,\n",
      "         7.5584e-01,  6.3213e-01,  5.3936e-01,  7.0635e-01,  6.7543e-01,\n",
      "         4.7132e-01,  6.2595e-01,  5.4554e-01,  2.7340e-01,  7.2491e-01,\n",
      "        -6.6783e-02,  2.2392e-01,  3.7854e-01,  6.1976e-01,  7.8058e-01,\n",
      "         7.9913e-01,  4.8988e-01,  5.2699e-01,  7.1254e-01,  1.6207e-01,\n",
      "         5.3317e-01,  5.7647e-01,  6.0121e-01,  3.7854e-01,  4.9606e-01,\n",
      "         6.6306e-01,  8.1660e-02,  6.5687e-01,  5.8265e-01,  5.7028e-01,\n",
      "         1.9918e-01,  7.6821e-01,  6.3832e-01,  4.1565e-01,  6.8161e-01,\n",
      "         3.2288e-01,  5.8884e-01,  5.0225e-01,  6.2595e-01,  5.7647e-01,\n",
      "        -2.6522e+00, -2.6522e+00,  6.5687e-01,  4.9606e-01,  1.0640e-01,\n",
      "         6.8161e-01,  6.0121e-01,  4.7132e-01,  6.1358e-01,  7.4347e-01,\n",
      "         3.9091e-01,  6.6924e-01,  7.7439e-01,  5.8265e-01,  7.3110e-01,\n",
      "         3.8473e-01,  7.4384e-03,  5.7647e-01,  7.8058e-01,  4.2184e-01,\n",
      "        -1.7193e-01,  4.0328e-01,  6.5687e-01,  6.6924e-01,  2.4247e-01,\n",
      "         6.1976e-01,  6.3213e-01,  6.0121e-01,  4.0328e-01,  6.7543e-01,\n",
      "         5.6410e-01,  6.3213e-01,  5.0843e-01,  7.0635e-01,  4.9606e-01,\n",
      "         1.9918e-01,  5.4554e-01,  3.0432e-01,  4.8988e-01,  2.2392e-01,\n",
      "         6.5069e-01,  6.2595e-01,  3.4762e-01,  5.0225e-01,  7.8676e-01,\n",
      "         3.7854e-01, -2.3487e-02,  3.8473e-01,  4.7132e-01,  4.6514e-01,\n",
      "         4.8369e-01,  5.6919e-02,  5.7028e-01,  5.1462e-01,  6.8161e-01,\n",
      "         6.6924e-01,  7.2491e-01,  6.9398e-01,  7.8058e-01,  5.8884e-01,\n",
      "         6.9289e-02,  8.1150e-01,  7.2491e-01,  4.1565e-01,  5.3936e-01,\n",
      "         2.3629e-01,  5.3936e-01,  4.9606e-01,  5.0225e-01,  1.2533e-03,\n",
      "         8.0532e-01,  5.5173e-01,  4.3421e-01,  5.5173e-01, -7.2968e-02,\n",
      "         3.9710e-01,  4.6514e-01,  6.7013e-01,  6.9398e-01,  5.0843e-01,\n",
      "         4.7132e-01,  4.8369e-01,  5.2080e-01,  6.5687e-01,  8.0532e-01,\n",
      "         7.0017e-01,  4.1565e-01,  6.5069e-01,  1.9918e-01, -4.8227e-02,\n",
      "         7.6202e-01, -4.9974e-01, -3.9459e-01,  5.8884e-01,  5.3936e-01,\n",
      "         6.3478e-01,  6.5687e-01,  2.8577e-01,  7.6202e-01,  2.7958e-01,\n",
      "         7.6202e-01,  4.0947e-01], device='cuda:0')\n",
      "| epoch   9 |   500/ 3424 batches | rmse    0.449\n",
      "| epoch   9 |  1000/ 3424 batches | rmse    0.582\n",
      "| epoch   9 |  1500/ 3424 batches | rmse    0.508\n",
      "| epoch   9 |  2000/ 3424 batches | rmse    0.359\n",
      "| epoch   9 |  2500/ 3424 batches | rmse    0.626\n",
      "| epoch   9 |  3000/ 3424 batches | rmse    0.665\n",
      "input shape:  torch.Size([8, 12, 207])\n",
      "output shape,  torch.Size([8, 12, 207])\n",
      "label shape:  torch.Size([8, 12, 207])\n",
      "out:  tensor([ 0.0389,  0.3405,  0.4344,  0.0871,  0.3167, -0.0619,  0.3262,  0.3106,\n",
      "         0.1560,  0.2761,  0.0632,  0.0766,  0.1884,  0.2504,  0.0554,  0.3210,\n",
      "        -0.9232,  0.1912, -0.2132,  0.2631,  0.4005, -0.0734, -0.3911, -0.0465,\n",
      "         0.4010, -0.0086,  0.0208,  0.1931,  0.4419, -0.3027,  0.0778,  0.3817,\n",
      "         0.4558,  0.3650,  0.3424, -0.0245,  0.3035,  0.1256,  0.3237, -0.0387,\n",
      "         0.3323,  0.3259,  0.2160,  0.2085,  0.2542,  0.2950,  0.1908,  0.1576,\n",
      "         0.2072,  0.0606, -0.1119, -0.3308,  0.3185, -0.1593,  0.1660,  0.1702,\n",
      "        -0.2723,  0.1342,  0.0141,  0.1578,  0.1195,  0.0549,  0.0489,  0.2267,\n",
      "         0.3917,  0.3128,  0.2834,  0.4071,  0.3649,  0.2512,  0.1838,  0.2693,\n",
      "         0.1330,  0.1199,  0.4241, -0.3206, -0.0285,  0.0535,  0.4603,  0.4231,\n",
      "         0.2943,  0.0437,  0.2142,  0.2923, -0.0086,  0.4056,  0.2866,  0.3080,\n",
      "         0.2976,  0.3634,  0.3985, -0.2389,  0.4135,  0.3440,  0.2778, -0.0147,\n",
      "         0.4750,  0.3689,  0.0936,  0.4092,  0.1717,  0.0964,  0.1053,  0.2504,\n",
      "         0.3580, -0.0194, -0.2614,  0.4398,  0.4469, -0.0670,  0.3345,  0.3669,\n",
      "         0.0807,  0.1423,  0.0425,  0.2128,  0.1791,  0.3447,  0.3118,  0.3781,\n",
      "         0.0460, -0.1622,  0.3746,  0.4640, -0.0383, -0.2986, -0.1070,  0.3227,\n",
      "         0.3746,  0.0531,  0.2196,  0.0784,  0.4579,  0.2313,  0.2616,  0.3157,\n",
      "         0.4083,  0.0892,  0.4077,  0.1309,  0.0044,  0.3076,  0.1932,  0.0655,\n",
      "        -0.0602,  0.3937,  0.2081,  0.0505,  0.3196,  0.1882,  0.3354,  0.0018,\n",
      "         0.0504,  0.1995,  0.1565,  0.2299, -0.1980,  0.2997,  0.1250,  0.3073,\n",
      "         0.2706,  0.4033,  0.3977,  0.4090,  0.1305, -0.2173,  0.2898,  0.4093,\n",
      "         0.4138,  0.4095, -0.0325,  0.3218,  0.0853,  0.3586, -0.7212,  0.3320,\n",
      "         0.4321,  0.2443,  0.2057, -0.1147, -0.1708, -0.0077,  0.3870,  0.5004,\n",
      "         0.3898,  0.2570,  0.2492,  0.1866,  0.3808,  0.0116,  0.3158,  0.3181,\n",
      "         0.2900,  0.2301, -0.1072,  0.4289, -0.8676, -0.6224,  0.3809,  0.0760,\n",
      "         0.1399,  0.3361,  0.2494,  0.4037,  0.2787,  0.3108,  0.1985],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "label:  tensor([ 5.3317e-01,  6.9398e-01,  6.6924e-01,  3.9091e-01,  6.5687e-01,\n",
      "         7.4965e-01,  5.7028e-01,  6.6924e-01,  2.9814e-01,  4.5277e-01,\n",
      "         9.4030e-02,  6.3832e-01,  5.2699e-01,  7.3728e-01,  3.3525e-01,\n",
      "         6.8780e-01, -7.8425e-01,  4.7132e-01,  3.0432e-01,  4.2184e-01,\n",
      "         6.7543e-01, -6.1107e-01,  5.0734e-02,  2.2392e-01,  5.7028e-01,\n",
      "         5.2699e-01,  3.7854e-01,  4.5277e-01,  6.5687e-01, -3.0800e-01,\n",
      "         1.6825e-01,  7.0017e-01,  5.7028e-01,  6.5687e-01,  5.1462e-01,\n",
      "         4.1565e-01,  5.3317e-01,  3.5380e-01,  3.5380e-01,  4.3421e-01,\n",
      "         5.3936e-01,  6.1358e-01,  4.1565e-01,  5.5791e-01,  1.1259e-01,\n",
      "         7.0017e-01,  4.6514e-01,  3.2288e-01,  3.2906e-01,  4.2803e-01,\n",
      "        -5.6159e-01, -2.6471e-01,  5.7028e-01,  4.8988e-01,  1.0640e-01,\n",
      "         3.4143e-01, -1.0036e-01,  3.2906e-01,  5.0843e-01,  3.1051e-01,\n",
      "         5.4554e-01,  5.1462e-01, -5.4413e-02,  6.2595e-01,  7.2491e-01,\n",
      "         7.5584e-01,  6.3213e-01,  5.3936e-01,  7.0635e-01,  6.7543e-01,\n",
      "         4.7132e-01,  6.2595e-01,  5.4554e-01,  2.7340e-01,  7.2491e-01,\n",
      "        -6.6783e-02,  2.2392e-01,  3.7854e-01,  6.1976e-01,  7.8058e-01,\n",
      "         7.9913e-01,  4.8988e-01,  5.2699e-01,  7.1254e-01,  1.6207e-01,\n",
      "         5.3317e-01,  5.7647e-01,  6.0121e-01,  3.7854e-01,  4.9606e-01,\n",
      "         6.6306e-01,  8.1660e-02,  6.5687e-01,  5.8265e-01,  5.7028e-01,\n",
      "         1.9918e-01,  7.6821e-01,  6.3832e-01,  4.1565e-01,  6.8161e-01,\n",
      "         3.2288e-01,  5.8884e-01,  5.0225e-01,  6.2595e-01,  5.7647e-01,\n",
      "        -2.6522e+00, -2.6522e+00,  6.5687e-01,  4.9606e-01,  1.0640e-01,\n",
      "         6.8161e-01,  6.0121e-01,  4.7132e-01,  6.1358e-01,  7.4347e-01,\n",
      "         3.9091e-01,  6.6924e-01,  7.7439e-01,  5.8265e-01,  7.3110e-01,\n",
      "         3.8473e-01,  7.4384e-03,  5.7647e-01,  7.8058e-01,  4.2184e-01,\n",
      "        -1.7193e-01,  4.0328e-01,  6.5687e-01,  6.6924e-01,  2.4247e-01,\n",
      "         6.1976e-01,  6.3213e-01,  6.0121e-01,  4.0328e-01,  6.7543e-01,\n",
      "         5.6410e-01,  6.3213e-01,  5.0843e-01,  7.0635e-01,  4.9606e-01,\n",
      "         1.9918e-01,  5.4554e-01,  3.0432e-01,  4.8988e-01,  2.2392e-01,\n",
      "         6.5069e-01,  6.2595e-01,  3.4762e-01,  5.0225e-01,  7.8676e-01,\n",
      "         3.7854e-01, -2.3487e-02,  3.8473e-01,  4.7132e-01,  4.6514e-01,\n",
      "         4.8369e-01,  5.6919e-02,  5.7028e-01,  5.1462e-01,  6.8161e-01,\n",
      "         6.6924e-01,  7.2491e-01,  6.9398e-01,  7.8058e-01,  5.8884e-01,\n",
      "         6.9289e-02,  8.1150e-01,  7.2491e-01,  4.1565e-01,  5.3936e-01,\n",
      "         2.3629e-01,  5.3936e-01,  4.9606e-01,  5.0225e-01,  1.2533e-03,\n",
      "         8.0532e-01,  5.5173e-01,  4.3421e-01,  5.5173e-01, -7.2968e-02,\n",
      "         3.9710e-01,  4.6514e-01,  6.7013e-01,  6.9398e-01,  5.0843e-01,\n",
      "         4.7132e-01,  4.8369e-01,  5.2080e-01,  6.5687e-01,  8.0532e-01,\n",
      "         7.0017e-01,  4.1565e-01,  6.5069e-01,  1.9918e-01, -4.8227e-02,\n",
      "         7.6202e-01, -4.9974e-01, -3.9459e-01,  5.8884e-01,  5.3936e-01,\n",
      "         6.3478e-01,  6.5687e-01,  2.8577e-01,  7.6202e-01,  2.7958e-01,\n",
      "         7.6202e-01,  4.0947e-01], device='cuda:0')\n",
      "| epoch  10 |   500/ 3424 batches | rmse    0.445\n",
      "| epoch  10 |  1000/ 3424 batches | rmse    0.583\n",
      "| epoch  10 |  1500/ 3424 batches | rmse    0.497\n",
      "| epoch  10 |  2000/ 3424 batches | rmse    0.356\n",
      "| epoch  10 |  2500/ 3424 batches | rmse    0.626\n",
      "| epoch  10 |  3000/ 3424 batches | rmse    0.705\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "import torch.nn.functional as F\n",
    "#from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "assert torch.cuda.is_available()\n",
    "# device = 'cuda'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyper parameters\n",
    "epochs = 10 # epoch\n",
    "lr = 0.001 # learning rate\n",
    "input_size = 207\n",
    "hidden_size = 32\n",
    "\n",
    "###########################################################################\n",
    "# TODO: Deinfe the classifier and loss function.\n",
    "###########################################################################\n",
    "model = TrafficLSTM(input_size=input_size, hidden_size=hidden_size, num_layers=3, sequence_len=12)\n",
    "loss_func = F.mse_loss\n",
    "###########################################################################\n",
    "#                             END OF YOUR CODE                            #\n",
    "###########################################################################\n",
    "\n",
    "# copy the model to the specified device (GPU)\n",
    "model = model.to(device)\n",
    "        \n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs, 1e-8)\n",
    "total_accu = None\n",
    "\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(model, loader, loss_func, device, optimizer)\n",
    "    #accu_val = evaluate(model, valid_dataloader, loss_func, device)\n",
    "    # if total_accu is not None and total_accu > accu_val:\n",
    "    #     scheduler.step()\n",
    "    # else:\n",
    "    #     total_accu = accu_val\n",
    "    # print('-' * 59)\n",
    "    # print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
    "    #       'valid accuracy {:8.3f} '.format(epoch,\n",
    "    #                                        time.time() - epoch_start_time,\n",
    "    #                                        accu_val))\n",
    "    # print('-' * 59)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "2c06b2b595a4244401d9d3d098afc4133f61971ccf670727ce6ecddf01477162"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
