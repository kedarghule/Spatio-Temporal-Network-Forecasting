{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric_temporal.dataset import METRLADatasetLoader\n",
    "from torch_geometric_temporal.signal import temporal_signal_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset\n",
    "\n",
    "loader = METRLADatasetLoader()\n",
    "\n",
    "dataset = loader.get_dataset()\n",
    "\n",
    "train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for simple LSTM\n",
    "\n",
    "class TrafficLSTM(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size:  int, num_layers: int, sequence_len: int):\n",
    "        super().__init__()\n",
    "        self.sequence_len = sequence_len\n",
    "        self.input_size = input_size\n",
    "        self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, batch_first = True)\n",
    "        # self.linear1 = nn.Linear(hidden_size*sequence_len, int(sequence_len*input_size/2))\n",
    "        # self.relu1 = nn.ReLU()\n",
    "        # self.linear2 = nn.Linear(int(sequence_len*input_size/2), sequence_len*input_size)\n",
    "        self.linear = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #batch_size = x.shape[0]\n",
    "        x, _ = self.lstm(x)\n",
    "        #x = x.reshape(batch_size, -1)\n",
    "        # #print(\"LSTM output: \", x.shape)\n",
    "        # x = self.linear1(x)\n",
    "        # #print(\"Linear output: \", x.shape)\n",
    "        # x = self.relu1(x)\n",
    "        # x = self.linear2(x)\n",
    "        # x = x.reshape(batch_size, self.sequence_len, self.input_size)\n",
    "        #x = x[:, -1, :]\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to take in features and make tensors of each point\n",
    "# here, we can decide how far out we want to predict\n",
    "# train will still be an hour of historical data\n",
    "# test initially contains next 12 timesteps\n",
    "# choose just one \n",
    "def create_dataset(train, test, timestep_to_predict=1):\n",
    "    train_data_x = np.array(train.features)\n",
    "    # just get speed\n",
    "    train_data_x = train_data_x[:,:,0,:]\n",
    "    N, S, T = train_data_x.shape\n",
    "    #print(N,S,T)\n",
    "    #train_data_x = train_data_x.reshape((N, S*T))\n",
    "    train_data_y = np.array(train.targets)\n",
    "    #train_data_y = train_data_y[:,:,timestep_to_predict].reshape(N, S, 1)\n",
    "    #train_data_y = train_data_y.reshape((N, S*T))\n",
    "    x_train = torch.tensor(train_data_x).swapaxes(1,2)\n",
    "    y_train = torch.tensor(train_data_y).swapaxes(1,2)\n",
    "    max_speed = torch.max(x_train)\n",
    "    min_speed = torch.min(x_train)\n",
    "    x_train = (x_train - min_speed)/(max_speed - min_speed)\n",
    "    y_train = (y_train - min_speed)/(max_speed - min_speed)\n",
    "    #x_train = torch.tensor(train_data_x)\n",
    "    #y_train = torch.tensor(train_data_y)\n",
    "    print(x_train.shape)\n",
    "    print(y_train.shape)\n",
    "    return data.TensorDataset(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27399, 12, 207])\n",
      "torch.Size([27399, 12, 207])\n",
      "label.shape: torch.Size([8, 12, 207])\n",
      "label: tensor([[[0.8732, 0.9571, 0.8357,  ..., 0.7589, 1.0000, 0.9071],\n",
      "         [0.8365, 0.8952, 0.9397,  ..., 0.7508, 0.9460, 0.8905],\n",
      "         [0.9089, 0.9571, 0.7857,  ..., 0.7750, 0.9607, 0.8339],\n",
      "         ...,\n",
      "         [0.8786, 0.8857, 0.8875,  ..., 0.8625, 1.0000, 0.8321],\n",
      "         [0.9032, 0.9159, 0.9190,  ..., 0.8889, 0.9619, 0.9000],\n",
      "         [0.9286, 0.9000, 0.9857,  ..., 0.8857, 0.9161, 0.8679]],\n",
      "\n",
      "        [[0.8365, 0.8952, 0.9397,  ..., 0.7508, 0.9460, 0.8905],\n",
      "         [0.9089, 0.9571, 0.7857,  ..., 0.7750, 0.9607, 0.8339],\n",
      "         [0.9540, 0.9365, 0.9730,  ..., 0.8730, 0.9746, 0.8778],\n",
      "         ...,\n",
      "         [0.9032, 0.9159, 0.9190,  ..., 0.8889, 0.9619, 0.9000],\n",
      "         [0.9286, 0.9000, 0.9857,  ..., 0.8857, 0.9161, 0.8679],\n",
      "         [0.7651, 0.9397, 0.9190,  ..., 0.9286, 0.8984, 0.8873]],\n",
      "\n",
      "        [[0.9089, 0.9571, 0.7857,  ..., 0.7750, 0.9607, 0.8339],\n",
      "         [0.9540, 0.9365, 0.9730,  ..., 0.8730, 0.9746, 0.8778],\n",
      "         [0.7982, 0.9357, 0.8679,  ..., 0.7304, 0.9429, 0.8612],\n",
      "         ...,\n",
      "         [0.9286, 0.9000, 0.9857,  ..., 0.8857, 0.9161, 0.8679],\n",
      "         [0.7651, 0.9397, 0.9190,  ..., 0.9286, 0.8984, 0.8873],\n",
      "         [0.8875, 0.9679, 0.9018,  ..., 0.8768, 0.9804, 0.7054]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.9190, 0.9429, 0.9746,  ..., 0.8492, 0.9889, 0.8873],\n",
      "         [0.9127, 0.8794, 0.9730,  ..., 0.8810, 0.9413, 0.7841],\n",
      "         [0.9018, 0.9125, 0.9339,  ..., 0.8429, 0.9571, 0.8250],\n",
      "         ...,\n",
      "         [0.8794, 0.9317, 0.9444,  ..., 0.9603, 0.9857, 0.8635],\n",
      "         [0.8554, 0.9161, 0.9607,  ..., 0.9607, 0.9393, 0.8982],\n",
      "         [0.9714, 0.9413, 0.9143,  ..., 0.9413, 0.9635, 0.8683]],\n",
      "\n",
      "        [[0.9127, 0.8794, 0.9730,  ..., 0.8810, 0.9413, 0.7841],\n",
      "         [0.9018, 0.9125, 0.9339,  ..., 0.8429, 0.9571, 0.8250],\n",
      "         [0.8875, 0.8750, 0.8679,  ..., 0.9196, 0.9464, 0.8000],\n",
      "         ...,\n",
      "         [0.8554, 0.9161, 0.9607,  ..., 0.9607, 0.9393, 0.8982],\n",
      "         [0.9714, 0.9413, 0.9143,  ..., 0.9413, 0.9635, 0.8683],\n",
      "         [0.9339, 0.9125, 0.9214,  ..., 0.8839, 0.9804, 0.8107]],\n",
      "\n",
      "        [[0.9018, 0.9125, 0.9339,  ..., 0.8429, 0.9571, 0.8250],\n",
      "         [0.8875, 0.8750, 0.8679,  ..., 0.9196, 0.9464, 0.8000],\n",
      "         [0.8786, 0.8857, 0.8875,  ..., 0.8625, 1.0000, 0.8321],\n",
      "         ...,\n",
      "         [0.9714, 0.9413, 0.9143,  ..., 0.9413, 0.9635, 0.8683],\n",
      "         [0.9339, 0.9125, 0.9214,  ..., 0.8839, 0.9804, 0.8107],\n",
      "         [0.9143, 0.9321, 0.8679,  ..., 0.9125, 0.9304, 0.7946]]])\n",
      "data.shape: torch.Size([8, 12, 207])\n"
     ]
    }
   ],
   "source": [
    "dataset = create_dataset(train_dataset, test_dataset)\n",
    "loader = data.DataLoader(dataset, batch_size = 8, drop_last=True)\n",
    "for idx, (data1, label) in enumerate(loader):\n",
    "    if idx > 0:\n",
    "        break\n",
    "    print('label.shape: {}'.format(label.shape))\n",
    "    print('label: {}'.format(label))\n",
    "    print('data.shape: {}'.format(data1.shape))\n",
    "# temp = next(iter(loader))\n",
    "# print(len(temp))\n",
    "# print(len(temp[0]))\n",
    "# print(len(temp[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(model, dataloader, loss_func, device, optimizer):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (data1, label) in enumerate(dataloader):\n",
    "        #label = label[:,-1,:]\n",
    "        label = label.to(device)\n",
    "        data1 = data1.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = None\n",
    "        ###########################################################################\n",
    "        # TODO: compute the logits of the input, get the loss, and do the         #\n",
    "        # gradient backpropagation.\n",
    "        ###########################################################################\n",
    "        if(idx == 0):\n",
    "            print(\"input shape: \", data1.shape)\n",
    "            print(\"label shape: \", label.shape)\n",
    "        out = model(data1)\n",
    "        out = out.swapaxes(1,2)\n",
    "        label = label.swapaxes(1,2)\n",
    "        if(idx == 0):\n",
    "            print(\"output shape, \", out.shape)\n",
    "            print(\"out: \", out[0][0])\n",
    "            print(\"label: \", label[0][0])\n",
    "        loss = loss_func(out, label)\n",
    "        loss.backward()\n",
    "        ###########################################################################\n",
    "        #                             END OF YOUR CODE                            #\n",
    "        ###########################################################################\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        train_rmse = torch.sqrt(loss)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                  '| rmse {:8.3f}'.format(epoch, idx, len(dataloader),\n",
    "                                              train_rmse))\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(model, dataloader, loss_func, device):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, data1) in enumerate(dataloader):\n",
    "            label = label.to(device)\n",
    "            data1 = data1.to(device)\n",
    "            \n",
    "            ###########################################################################\n",
    "            # TODO: compute the logits of the input, get the loss.                    #\n",
    "            ###########################################################################\n",
    "            logits = model(data1)\n",
    "            loss = loss_func(logits, label)\n",
    "            ###########################################################################\n",
    "            #                             END OF YOUR CODE                            #\n",
    "            ###########################################################################\n",
    "            \n",
    "            total_acc += (logits.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape:  torch.Size([8, 12, 207])\n",
      "label shape:  torch.Size([8, 12, 207])\n",
      "output shape,  torch.Size([8, 207, 12])\n",
      "out:  tensor([0.0632, 0.0631, 0.0602, 0.0588, 0.0589, 0.0577, 0.0561, 0.0544, 0.0530,\n",
      "        0.0519, 0.0511, 0.0503], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "label:  tensor([0.8732, 0.8365, 0.9089, 0.9540, 0.7982, 0.9190, 0.9127, 0.9018, 0.8875,\n",
      "        0.8786, 0.9032, 0.9286], device='cuda:0')\n",
      "| epoch   1 |   500/ 3424 batches | rmse    0.219\n",
      "| epoch   1 |  1000/ 3424 batches | rmse    0.209\n",
      "| epoch   1 |  1500/ 3424 batches | rmse    0.198\n",
      "| epoch   1 |  2000/ 3424 batches | rmse    0.352\n",
      "| epoch   1 |  2500/ 3424 batches | rmse    0.182\n",
      "| epoch   1 |  3000/ 3424 batches | rmse    0.263\n",
      "input shape:  torch.Size([8, 12, 207])\n",
      "label shape:  torch.Size([8, 12, 207])\n",
      "output shape,  torch.Size([8, 207, 12])\n",
      "out:  tensor([0.7810, 0.8227, 0.8320, 0.6307, 0.4337, 0.8279, 0.8335, 0.8351, 0.8359,\n",
      "        0.8359, 0.8359, 0.8359], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "label:  tensor([0.8732, 0.8365, 0.9089, 0.9540, 0.7982, 0.9190, 0.9127, 0.9018, 0.8875,\n",
      "        0.8786, 0.9032, 0.9286], device='cuda:0')\n",
      "| epoch   2 |   500/ 3424 batches | rmse    0.164\n",
      "| epoch   2 |  1000/ 3424 batches | rmse    0.121\n",
      "| epoch   2 |  1500/ 3424 batches | rmse    0.192\n",
      "| epoch   2 |  2000/ 3424 batches | rmse    0.176\n",
      "| epoch   2 |  2500/ 3424 batches | rmse    0.181\n",
      "| epoch   2 |  3000/ 3424 batches | rmse    0.261\n",
      "input shape:  torch.Size([8, 12, 207])\n",
      "label shape:  torch.Size([8, 12, 207])\n",
      "output shape,  torch.Size([8, 207, 12])\n",
      "out:  tensor([0.7666, 0.7836, 0.7958, 0.7965, 0.7966, 0.7984, 0.7982, 0.7982, 0.7983,\n",
      "        0.7983, 0.7983, 0.7983], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "label:  tensor([0.8732, 0.8365, 0.9089, 0.9540, 0.7982, 0.9190, 0.9127, 0.9018, 0.8875,\n",
      "        0.8786, 0.9032, 0.9286], device='cuda:0')\n",
      "| epoch   3 |   500/ 3424 batches | rmse    0.164\n",
      "| epoch   3 |  1000/ 3424 batches | rmse    0.120\n",
      "| epoch   3 |  1500/ 3424 batches | rmse    0.192\n",
      "| epoch   3 |  2000/ 3424 batches | rmse    0.239\n",
      "| epoch   3 |  2500/ 3424 batches | rmse    0.182\n",
      "| epoch   3 |  3000/ 3424 batches | rmse    0.242\n",
      "input shape:  torch.Size([8, 12, 207])\n",
      "label shape:  torch.Size([8, 12, 207])\n",
      "output shape,  torch.Size([8, 207, 12])\n",
      "out:  tensor([0.8655, 0.8821, 0.8960, 0.5302, 0.4670, 0.8889, 0.8976, 0.8984, 0.8989,\n",
      "        0.8990, 0.8990, 0.8990], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "label:  tensor([0.8732, 0.8365, 0.9089, 0.9540, 0.7982, 0.9190, 0.9127, 0.9018, 0.8875,\n",
      "        0.8786, 0.9032, 0.9286], device='cuda:0')\n",
      "| epoch   4 |   500/ 3424 batches | rmse    0.140\n",
      "| epoch   4 |  1000/ 3424 batches | rmse    0.101\n",
      "| epoch   4 |  1500/ 3424 batches | rmse    0.199\n",
      "| epoch   4 |  2000/ 3424 batches | rmse    0.188\n",
      "| epoch   4 |  2500/ 3424 batches | rmse    0.182\n",
      "| epoch   4 |  3000/ 3424 batches | rmse    0.242\n",
      "input shape:  torch.Size([8, 12, 207])\n",
      "label shape:  torch.Size([8, 12, 207])\n",
      "output shape,  torch.Size([8, 207, 12])\n",
      "out:  tensor([0.8791, 0.8715, 0.8741, 0.5866, 0.5588, 0.8915, 0.8737, 0.8762, 0.8755,\n",
      "        0.8752, 0.8753, 0.8750], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "label:  tensor([0.8732, 0.8365, 0.9089, 0.9540, 0.7982, 0.9190, 0.9127, 0.9018, 0.8875,\n",
      "        0.8786, 0.9032, 0.9286], device='cuda:0')\n",
      "| epoch   5 |   500/ 3424 batches | rmse    0.123\n",
      "| epoch   5 |  1000/ 3424 batches | rmse    0.106\n",
      "| epoch   5 |  1500/ 3424 batches | rmse    0.200\n",
      "| epoch   5 |  2000/ 3424 batches | rmse    0.169\n",
      "| epoch   5 |  2500/ 3424 batches | rmse    0.182\n",
      "| epoch   5 |  3000/ 3424 batches | rmse    0.244\n",
      "input shape:  torch.Size([8, 12, 207])\n",
      "label shape:  torch.Size([8, 12, 207])\n",
      "output shape,  torch.Size([8, 207, 12])\n",
      "out:  tensor([0.8742, 0.8776, 0.8887, 0.6570, 0.5238, 0.9208, 0.8933, 0.8911, 0.8914,\n",
      "        0.8914, 0.8915, 0.8914], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "label:  tensor([0.8732, 0.8365, 0.9089, 0.9540, 0.7982, 0.9190, 0.9127, 0.9018, 0.8875,\n",
      "        0.8786, 0.9032, 0.9286], device='cuda:0')\n",
      "| epoch   6 |   500/ 3424 batches | rmse    0.124\n",
      "| epoch   6 |  1000/ 3424 batches | rmse    0.118\n",
      "| epoch   6 |  1500/ 3424 batches | rmse    0.193\n",
      "| epoch   6 |  2000/ 3424 batches | rmse    0.160\n",
      "| epoch   6 |  2500/ 3424 batches | rmse    0.182\n",
      "| epoch   6 |  3000/ 3424 batches | rmse    0.241\n",
      "input shape:  torch.Size([8, 12, 207])\n",
      "label shape:  torch.Size([8, 12, 207])\n",
      "output shape,  torch.Size([8, 207, 12])\n",
      "out:  tensor([0.8802, 0.8748, 0.8871, 0.6931, 0.5700, 0.9176, 0.8914, 0.8903, 0.8902,\n",
      "        0.8902, 0.8901, 0.8901], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "label:  tensor([0.8732, 0.8365, 0.9089, 0.9540, 0.7982, 0.9190, 0.9127, 0.9018, 0.8875,\n",
      "        0.8786, 0.9032, 0.9286], device='cuda:0')\n",
      "| epoch   7 |   500/ 3424 batches | rmse    0.126\n",
      "| epoch   7 |  1000/ 3424 batches | rmse    0.109\n",
      "| epoch   7 |  1500/ 3424 batches | rmse    0.170\n",
      "| epoch   7 |  2000/ 3424 batches | rmse    0.158\n",
      "| epoch   7 |  2500/ 3424 batches | rmse    0.180\n",
      "| epoch   7 |  3000/ 3424 batches | rmse    0.244\n",
      "input shape:  torch.Size([8, 12, 207])\n",
      "label shape:  torch.Size([8, 12, 207])\n",
      "output shape,  torch.Size([8, 207, 12])\n",
      "out:  tensor([0.8882, 0.8758, 0.8925, 0.7080, 0.5567, 0.9265, 0.8954, 0.8983, 0.8978,\n",
      "        0.8986, 0.8965, 0.8969], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "label:  tensor([0.8732, 0.8365, 0.9089, 0.9540, 0.7982, 0.9190, 0.9127, 0.9018, 0.8875,\n",
      "        0.8786, 0.9032, 0.9286], device='cuda:0')\n",
      "| epoch   8 |   500/ 3424 batches | rmse    0.127\n",
      "| epoch   8 |  1000/ 3424 batches | rmse    0.104\n",
      "| epoch   8 |  1500/ 3424 batches | rmse    0.169\n",
      "| epoch   8 |  2000/ 3424 batches | rmse    0.151\n",
      "| epoch   8 |  2500/ 3424 batches | rmse    0.175\n",
      "| epoch   8 |  3000/ 3424 batches | rmse    0.243\n",
      "input shape:  torch.Size([8, 12, 207])\n",
      "label shape:  torch.Size([8, 12, 207])\n",
      "output shape,  torch.Size([8, 207, 12])\n",
      "out:  tensor([0.8764, 0.8634, 0.8738, 0.6641, 0.5175, 0.9183, 0.8790, 0.8794, 0.8787,\n",
      "        0.8799, 0.8772, 0.8775], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "label:  tensor([0.8732, 0.8365, 0.9089, 0.9540, 0.7982, 0.9190, 0.9127, 0.9018, 0.8875,\n",
      "        0.8786, 0.9032, 0.9286], device='cuda:0')\n",
      "| epoch   9 |   500/ 3424 batches | rmse    0.128\n",
      "| epoch   9 |  1000/ 3424 batches | rmse    0.097\n",
      "| epoch   9 |  1500/ 3424 batches | rmse    0.180\n",
      "| epoch   9 |  2000/ 3424 batches | rmse    0.160\n",
      "| epoch   9 |  2500/ 3424 batches | rmse    0.175\n",
      "| epoch   9 |  3000/ 3424 batches | rmse    0.242\n",
      "input shape:  torch.Size([8, 12, 207])\n",
      "label shape:  torch.Size([8, 12, 207])\n",
      "output shape,  torch.Size([8, 207, 12])\n",
      "out:  tensor([0.8590, 0.8484, 0.8620, 0.6550, 0.5451, 0.9174, 0.8681, 0.8658, 0.8658,\n",
      "        0.8660, 0.8657, 0.8658], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "label:  tensor([0.8732, 0.8365, 0.9089, 0.9540, 0.7982, 0.9190, 0.9127, 0.9018, 0.8875,\n",
      "        0.8786, 0.9032, 0.9286], device='cuda:0')\n",
      "| epoch  10 |   500/ 3424 batches | rmse    0.132\n",
      "| epoch  10 |  1000/ 3424 batches | rmse    0.099\n",
      "| epoch  10 |  1500/ 3424 batches | rmse    0.168\n",
      "| epoch  10 |  2000/ 3424 batches | rmse    0.152\n",
      "| epoch  10 |  2500/ 3424 batches | rmse    0.170\n",
      "| epoch  10 |  3000/ 3424 batches | rmse    0.242\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "import torch.nn.functional as F\n",
    "#from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "assert torch.cuda.is_available()\n",
    "# device = 'cuda'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyper parameters\n",
    "epochs = 10 # epoch\n",
    "lr = 0.001 # learning rate\n",
    "input_size = 207\n",
    "hidden_size = 128\n",
    "\n",
    "###########################################################################\n",
    "# TODO: Deinfe the classifier and loss function.\n",
    "###########################################################################\n",
    "model = TrafficLSTM(input_size=input_size, hidden_size=hidden_size, num_layers=3, sequence_len=12)\n",
    "loss_func = F.mse_loss\n",
    "###########################################################################\n",
    "#                             END OF YOUR CODE                            #\n",
    "###########################################################################\n",
    "\n",
    "# copy the model to the specified device (GPU)\n",
    "model = model.to(device)\n",
    "        \n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs, 1e-8)\n",
    "total_accu = None\n",
    "\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(model, loader, loss_func, device, optimizer)\n",
    "    #accu_val = evaluate(model, valid_dataloader, loss_func, device)\n",
    "    # if total_accu is not None and total_accu > accu_val:\n",
    "    #     scheduler.step()\n",
    "    # else:\n",
    "    #     total_accu = accu_val\n",
    "    # print('-' * 59)\n",
    "    # print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
    "    #       'valid accuracy {:8.3f} '.format(epoch,\n",
    "    #                                        time.time() - epoch_start_time,\n",
    "    #                                        accu_val))\n",
    "    # print('-' * 59)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
